{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on W-jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "# from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization\n",
    "# from tensorflow.keras.layers import Conv1D\n",
    "# from tensorflow.keras.layers import Flatten, Reshape, Lambda\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# from tensorflow.keras import Model\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#from scipy import linalg as LA\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.tf_sinkhorn import ground_distance_tf_nograd, sinkhorn_knopp_tf_scaling_stabilized_class\n",
    "import utils.VAE_model_tools\n",
    "from utils.VAE_model_tools import build_and_compile_annealing_vae, betaVAEModel, reset_metrics\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    ''' Creates a directory (or nested directories) if they don't exist.\n",
    "    '''\n",
    "    if not osp.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    return dir_path\n",
    "\n",
    "def ptetaphiE_to_Epxpypz(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    px = pt * np.cos(phi)\n",
    "    py = pt * np.sin(phi)\n",
    "    pz = pt * np.sinh(eta)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = E\n",
    "    newjets[:,:,1] = px\n",
    "    newjets[:,:,2] = py\n",
    "    newjets[:,:,3] = pz\n",
    "    \n",
    "    return newjets\n",
    "\n",
    "def ptetaphiE_to_ptyphim(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    pz = pt * np.sinh(eta)\n",
    "    y = 0.5*np.nan_to_num(np.log((E+pz)/(E-pz)))\n",
    "    \n",
    "    msqr = np.square(E)-np.square(pt)-np.square(pz)\n",
    "    msqr[np.abs(msqr) < 1e-6] = 0\n",
    "    m = np.sqrt(msqr)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = y\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = m\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def ptyphim_to_ptetaphiE(jets):\n",
    "    \n",
    "    pt = jets[:,:,0]\n",
    "    y = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    m = jets[:,:,3]\n",
    "    \n",
    "    eta = np.nan_to_num(np.arcsinh(np.sinh(y)*np.sqrt(1+np.square(m/pt))))\n",
    "    pz = pt * np.sinh(eta)\n",
    "    E = np.sqrt(np.square(pz)+np.square(pt)+np.square(m))\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = eta\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = E\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def center_jets_ptetaphiE(jets):\n",
    "    cartesian_jets = ptetaphiE_to_Epxpypz(jets)\n",
    "    sumjet_cartesian = np.sum(cartesian_jets,axis=1)\n",
    "    \n",
    "    sumjet_phi = np.arctan2(sumjet_cartesian[:,2],sumjet_cartesian[:,1])\n",
    "    sumjet_y = 0.5*np.log((sumjet_cartesian[:,0] + sumjet_cartesian[:,-1])/(sumjet_cartesian[:,0] - sumjet_cartesian[:,-1]))\n",
    "    \n",
    "    ptyphim_jets = ptetaphiE_to_ptyphim(jets)\n",
    "    #print(ptyphim_jets[:3,:,:])\n",
    "    \n",
    "    transformed_jets = np.copy(ptyphim_jets)\n",
    "    transformed_jets[:,:,1] = ptyphim_jets[:,:,1] - sumjet_y[:,None]\n",
    "    transformed_jets[:,:,2] = ptyphim_jets[:,:,2] - sumjet_phi[:,None]\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] + np.pi\n",
    "    transformed_jets[:,:,2] = np.mod(transformed_jets[:,:,2],2*np.pi)\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] - np.pi\n",
    "\n",
    "    transformed_jets[transformed_jets[:,:,0] == 0] = 0\n",
    "    \n",
    "    newjets = ptyphim_to_ptetaphiE(transformed_jets)\n",
    "    return newjets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(602055, 200)\n",
      "Memory in GB: 1.803235039114952\n"
     ]
    }
   ],
   "source": [
    "# path to file\n",
    "fn =  '/global/home/users/yifengh3/data/monoW-data-3.h5'\n",
    "# fn =  '/media/jcollins/MAGIC!/monoW-data-3.h5'\n",
    "\n",
    "# Option 1: Load everything into memory\n",
    "df = pandas.read_hdf(fn,stop=1000000)\n",
    "print(df.shape)\n",
    "print(\"Memory in GB:\",sum(df.memory_usage(deep=True)) / (1024**3)+sum(df.memory_usage(deep=True)) / (1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-1fefca2ae6f7>:34: RuntimeWarning: invalid value encountered in true_divide\n",
      "  y = 0.5*np.nan_to_num(np.log((E+pz)/(E-pz)))\n",
      "<ipython-input-4-1fefca2ae6f7>:55: RuntimeWarning: invalid value encountered in true_divide\n",
      "  eta = np.nan_to_num(np.arcsinh(np.sinh(y)*np.sqrt(1+np.square(m/pt))))\n"
     ]
    }
   ],
   "source": [
    "# Data file contains, for each event, 50 particles (with zero padding), each particle with pT, eta, phi, E.\n",
    "data = df.values.reshape((-1,50,4))\n",
    "\n",
    "# Normalize pTs so that HT = 1\n",
    "HT = np.sum(data[:,:,0],axis=-1)\n",
    "data[:,:,0] = data[:,:,0]/HT[:,None]\n",
    "data[:,:,-1] = data[:,:,-1]/HT[:,None]\n",
    "\n",
    "# Center jet (optional)\n",
    "data = center_jets_ptetaphiE(data)\n",
    "\n",
    "# Inputs x to NN will be: pT, eta, cos(phi), sin(phi), log E\n",
    "# Separated phi into cos and sin for continuity around full detector, so make things easier for NN.\n",
    "# Also adding the log E is mainly because it seems like it should make things easier for NN, since there is an exponential spread in particle energies.\n",
    "# Feel free to change these choices as desired. E.g. px, py might be equally as good as pt, sin, cos.\n",
    "sig_input = np.zeros((len(data),50,5))\n",
    "sig_input[:,:,:2] = data[:,:,:2]\n",
    "sig_input[:,:,2] = np.cos(data[:,:,2])\n",
    "sig_input[:,:,3] = np.sin(data[:,:,2])\n",
    "sig_input[:,:,4] = np.log(data[:,:,3]+1e-8)\n",
    "\n",
    "\n",
    "data_x = sig_input\n",
    "# Event 'labels' y are [pT, eta, phi], which is used to calculate EMD to output which is also pT, eta, phi.\n",
    "data_y = data[:,:,:3]\n",
    "\n",
    "\n",
    "train_x = data_x[:500000]\n",
    "train_y = data_y[:500000]\n",
    "valid_x = data_x[500000:600000]\n",
    "valid_y = data_y[500000:600000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 50, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 50, 1024)     6144        inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 50, 1024)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 50, 1024)     1049600     re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 50, 1024)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 50, 1028)     1053700     re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 50, 1028)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 50, 1024)     1053696     re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 50, 1024)     0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 1024)         0           re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1028)         1053700     tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 1028)         0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1028)         1057812     re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 1028)         0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1028)         1057812     re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_18 (ReLU)                 (None, 1028)         0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 512)          526848      re_lu_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 512)          0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          65664       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          65664       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            multiple             6990640     inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack_1 (TFOpLambda)         (2, None, 128)       0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 50, 3)        380360      encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gauss_distribution (Dis multiple             0           tf.stack_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 7,371,001\n",
      "Trainable params: 7,371,000\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:AutoGraph could not transform <function build_and_compile_annealing_vae.<locals>.recon_loss at 0x7fe6c44fbca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function build_and_compile_annealing_vae.<locals>.recon_loss at 0x7fe6c44fbca0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3112.0137 - recon_loss: 2.6613 - KL loss: 3110.6831 - beta: 1.0000 - val_loss: 150237.0469 - val_recon_loss: 12.4178 - val_KL loss: 150230.8438 - val_beta: 1.0000\n"
     ]
    }
   ],
   "source": [
    "output_dir = './output/'\n",
    "\n",
    "experiment_name = 'W-test_smooth'\n",
    "train_output_dir = create_dir(osp.join(output_dir, experiment_name))\n",
    "vae, encoder, decoder = build_and_compile_annealing_vae(optimizer=keras.optimizers.Adam(lr=0.001,clipnorm=0.1),\n",
    "                                    encoder_conv_layers = [1024,1024,1028,1024],\n",
    "                                    dense_size = [1028,1028,1028,512],\n",
    "                                    decoder = [2048,2048,1028,512,512],\n",
    "                                    numItermaxinner = 40,   # EMD approximation params\n",
    "                                    numIter=10,\n",
    "                                    reg_init = 1.,\n",
    "                                    reg_final = 0.01,\n",
    "                                    stopThr=1e-3,\n",
    "                                    num_inputs=5,           # Size of x (e.g. pT, eta, sin, cos, log E)\n",
    "                                    num_particles_in=50)    # Num particles per event.\n",
    "\n",
    "batch_size=100\n",
    "save_period=2\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(train_output_dir + '/model_weights_{epoch:02d}.hdf5', save_freq = save_period*5000, save_weights_only=True)\n",
    "reset_metrics_inst = reset_metrics()\n",
    "\n",
    "callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "\n",
    "\n",
    "# Need to train on at least one example before model params can be loaded for annoying reasons.\n",
    "\n",
    "history = vae.fit(x=train_x[:10], y=train_y[:10], batch_size=batch_size,\n",
    "                epochs=1,verbose=1,#initial_epoch=int(vae.optimizer.iterations/numbatches),\n",
    "                validation_data = (valid_x[:10],valid_y[:10]),\n",
    "                callbacks = callbacks\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 99ms/step - loss: 14034072.6364 - recon_loss: 0.2807 - KL loss: 10.7357 - beta: 1.0000e-04 - val_loss: 4466860.0000 - val_recon_loss: 0.0893 - val_KL loss: 80.9163 - val_beta: 1.0000e-04\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 797692.3011 - recon_loss: 0.0565 - KL loss: 172.7263 - beta: 1.8821e-04 - val_loss: 300122.0312 - val_recon_loss: 0.0212 - val_KL loss: 520.5480 - val_beta: 1.8821e-04\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 83451.5923 - recon_loss: 0.0208 - KL loss: 580.2442 - beta: 3.5424e-04 - val_loss: 70104.5078 - val_recon_loss: 0.0174 - val_KL loss: 698.8943 - val_beta: 3.5424e-04\n",
      "10/10 [==============================] - 1s 98ms/step - loss: 19043.5360 - recon_loss: 0.0163 - KL loss: 677.3378 - beta: 6.6673e-04 - val_loss: 18210.3691 - val_recon_loss: 0.0156 - val_KL loss: 609.1655 - val_beta: 6.6673e-04\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 5178.1443 - recon_loss: 0.0145 - KL loss: 581.4078 - beta: 0.0013 - val_loss: 5023.4580 - val_recon_loss: 0.0144 - val_KL loss: 450.3717 - val_beta: 0.0013\n",
      "10/10 [==============================] - 1s 113ms/step - loss: 1729.9551 - recon_loss: 0.0147 - KL loss: 408.0349 - beta: 0.0024 - val_loss: 1687.8040 - val_recon_loss: 0.0154 - val_KL loss: 305.3618 - val_beta: 0.0024\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 641.7789 - recon_loss: 0.0150 - KL loss: 261.2873 - beta: 0.0044 - val_loss: 616.0528 - val_recon_loss: 0.0173 - val_KL loss: 177.0611 - val_beta: 0.0044\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 284.8110 - recon_loss: 0.0183 - KL loss: 153.9518 - beta: 0.0084 - val_loss: 256.1173 - val_recon_loss: 0.0224 - val_KL loss: 96.2144 - val_beta: 0.0084\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 131.7226 - recon_loss: 0.0255 - KL loss: 80.3572 - beta: 0.0157 - val_loss: 112.7339 - val_recon_loss: 0.0299 - val_KL loss: 52.3532 - val_beta: 0.0157\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 63.0168 - recon_loss: 0.0308 - KL loss: 45.5020 - beta: 0.0296 - val_loss: 44.2591 - val_recon_loss: 0.0524 - val_KL loss: 14.4357 - val_beta: 0.0296\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 19.8706 - recon_loss: 0.0612 - KL loss: 10.0402 - beta: 0.0558 - val_loss: 13.7115 - val_recon_loss: 0.0677 - val_KL loss: 2.8394 - val_beta: 0.0558\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 4.9423 - recon_loss: 0.0688 - KL loss: 1.8198 - beta: 0.1050 - val_loss: 3.1324 - val_recon_loss: 0.0638 - val_KL loss: 0.2381 - val_beta: 0.1050\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.8522 - recon_loss: 0.0553 - KL loss: 0.1440 - beta: 0.1976 - val_loss: 0.5458 - val_recon_loss: 0.0409 - val_KL loss: 0.0222 - val_beta: 0.1976\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 0.1511 - recon_loss: 0.0379 - KL loss: 0.0140 - beta: 0.3719 - val_loss: 0.1026 - val_recon_loss: 0.0282 - val_KL loss: 8.2470e-04 - val_beta: 0.3719\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.0284 - recon_loss: 0.0271 - KL loss: 6.9469e-04 - beta: 0.7000 - val_loss: 0.0239 - val_recon_loss: 0.0226 - val_KL loss: 8.2374e-04 - val_beta: 0.7000\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 0.0558 - recon_loss: 0.0213 - KL loss: 7.0084e-04 - beta: 0.4393 - val_loss: 0.0492 - val_recon_loss: 0.0188 - val_KL loss: 5.4527e-04 - val_beta: 0.4393\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.1235 - recon_loss: 0.0187 - KL loss: 5.3198e-04 - beta: 0.2756 - val_loss: 0.1146 - val_recon_loss: 0.0173 - val_KL loss: 5.3408e-04 - val_beta: 0.2756\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.2838 - recon_loss: 0.0170 - KL loss: 5.2396e-04 - beta: 0.1730 - val_loss: 0.2604 - val_recon_loss: 0.0155 - val_KL loss: 0.0013 - val_beta: 0.1730\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.6540 - recon_loss: 0.0154 - KL loss: 8.0384e-04 - beta: 0.1085 - val_loss: 0.6506 - val_recon_loss: 0.0153 - val_KL loss: 5.0148e-04 - val_beta: 0.1085\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 1.5883 - recon_loss: 0.0147 - KL loss: 5.2918e-04 - beta: 0.0681 - val_loss: 1.5437 - val_recon_loss: 0.0143 - val_KL loss: 4.6215e-04 - val_beta: 0.0681\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 3.8709 - recon_loss: 0.0141 - KL loss: 0.0030 - beta: 0.0427 - val_loss: 4.0440 - val_recon_loss: 0.0148 - val_KL loss: 0.0012 - val_beta: 0.0427\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 9.7166 - recon_loss: 0.0140 - KL loss: 0.0100 - beta: 0.0268 - val_loss: 9.6760 - val_recon_loss: 0.0139 - val_KL loss: 0.0022 - val_beta: 0.0268\n",
      "10/10 [==============================] - 1s 90ms/step - loss: 24.2968 - recon_loss: 0.0137 - KL loss: 0.0355 - beta: 0.0168 - val_loss: 24.2947 - val_recon_loss: 0.0137 - val_KL loss: 0.0593 - val_beta: 0.0168\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 61.0798 - recon_loss: 0.0136 - KL loss: 0.0984 - beta: 0.0106 - val_loss: 60.5750 - val_recon_loss: 0.0135 - val_KL loss: 0.1759 - val_beta: 0.0106\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 154.3513 - recon_loss: 0.0135 - KL loss: 0.2666 - beta: 0.0066 - val_loss: 150.6484 - val_recon_loss: 0.0132 - val_KL loss: 0.7329 - val_beta: 0.0066\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 369.5092 - recon_loss: 0.0127 - KL loss: 1.0616 - beta: 0.0042 - val_loss: 372.6558 - val_recon_loss: 0.0128 - val_KL loss: 2.1831 - val_beta: 0.0042\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 945.8952 - recon_loss: 0.0128 - KL loss: 2.8189 - beta: 0.0026 - val_loss: 950.8694 - val_recon_loss: 0.0129 - val_KL loss: 4.2992 - val_beta: 0.0026\n",
      "10/10 [==============================] - 1s 88ms/step - loss: 2385.9634 - recon_loss: 0.0128 - KL loss: 4.6391 - beta: 0.0016 - val_loss: 2466.0657 - val_recon_loss: 0.0132 - val_KL loss: 6.6804 - val_beta: 0.0016\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 6049.3834 - recon_loss: 0.0128 - KL loss: 7.7885 - beta: 0.0010 - val_loss: 6067.8799 - val_recon_loss: 0.0128 - val_KL loss: 12.5648 - val_beta: 0.0010\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 15244.9981 - recon_loss: 0.0127 - KL loss: 14.2569 - beta: 6.4490e-04 - val_loss: 14961.3057 - val_recon_loss: 0.0124 - val_KL loss: 19.4007 - val_beta: 6.4490e-04\n",
      "10/10 [==============================] - 1s 97ms/step - loss: 38101.6644 - recon_loss: 0.0125 - KL loss: 19.9539 - beta: 4.0469e-04 - val_loss: 39738.5195 - val_recon_loss: 0.0130 - val_KL loss: 18.8068 - val_beta: 4.0469e-04\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 95550.8075 - recon_loss: 0.0123 - KL loss: 19.8072 - beta: 2.5395e-04 - val_loss: 99416.6562 - val_recon_loss: 0.0128 - val_KL loss: 26.3321 - val_beta: 2.5395e-04\n",
      "10/10 [==============================] - 1s 92ms/step - loss: 235202.5980 - recon_loss: 0.0119 - KL loss: 29.5736 - beta: 1.5936e-04 - val_loss: 244157.3906 - val_recon_loss: 0.0124 - val_KL loss: 38.5117 - val_beta: 1.5936e-04\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 610911.4773 - recon_loss: 0.0122 - KL loss: 39.4131 - beta: 1.0000e-04 - val_loss: 621506.0625 - val_recon_loss: 0.0124 - val_KL loss: 41.9884 - val_beta: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "init_epoch = 0\n",
    "steps_per_epoch = 10\n",
    "epoch_per_beta = 1\n",
    "# save_period = 10\n",
    "total_epoch = 0\n",
    "changing_level = 100\n",
    "beta_space = np.concatenate((np.logspace(-4,np.log10(0.7),changing_level),\n",
    "               np.logspace(np.log10(0.7),-4,changing_level)[1:]))\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "# earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='epoch',min_delta=epoch_per_beta,patience=0,mode=\"max\")\n",
    "\n",
    "for beta in beta_space:\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=epoch_per_beta,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    total_epoch+=epoch_per_beta\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(total_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe69c1a3190>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "beta_space=np.concatenate((np.logspace(-4,np.log10(0.7),15),\n",
    "               np.logspace(np.log10(0.7),-4,20)[1:]))\n",
    "plt.plot(beta_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log.csv                            model_weights_end_4_6.7e-04.hdf5\r\n",
      "model_weights_end_0_1.0e-04.hdf5   model_weights_end_5_1.3e-03.hdf5\r\n",
      "model_weights_end_10_3.0e-02.hdf5  model_weights_end_6_2.4e-03.hdf5\r\n",
      "model_weights_end_1_1.0e-04.hdf5   model_weights_end_7_4.4e-03.hdf5\r\n",
      "model_weights_end_11_5.6e-02.hdf5  model_weights_end_8_8.4e-03.hdf5\r\n",
      "model_weights_end_2_1.9e-04.hdf5   model_weights_end_9_1.6e-02.hdf5\r\n",
      "model_weights_end_3_3.5e-04.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "%ls output/W-test_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init_epoch = 544\n",
    "steps_per_epoch = 1000\n",
    "save_period = 10\n",
    "\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_val_loss', min_delta=0., patience=10, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "\n",
    "for beta in np.concatenate((np.logspace(-4,np.log10(0.7),15),\n",
    "               np.logspace(np.log10(0.7),-5,20)[1:],\n",
    "                np.logspace(-5,np.log10(0.7),20)[1:])):\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint('/media/sda1/train-W' + '/model_weights_{epoch:02d}_' + \"{:.1e}\".format(beta) + '.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[344577]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x[344599:344699]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output_dir + '/model_weights_{epoch:02d}_' + str(beta) + '.hdf5'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
