{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef50705",
   "metadata": {},
   "source": [
    "# Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05a505b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "train, val, test = 0.7, 0.2, 0.1\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 500\n",
    "batch_size = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aa5d4",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25276321",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_signal_file = \"/global/home/users/yifengh3/VAE/data/B_signal.h5\"\n",
    "background_file = \"/global/home/users/yifengh3/VAE/data/B_background.h5\"\n",
    "b_signal_data = pandas.read_hdf(b_signal_file)\n",
    "background_data = pandas.read_hdf(background_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646d74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgroubackground_datand data shape: (2000000, 150)\n",
      "B signal data shape: (50000, 150)\n"
     ]
    }
   ],
   "source": [
    "print(\"backgroubackground_datand data shape: {}\".format(background_data.shape))\n",
    "print(\"B signal data shape: {}\".format(b_signal_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e582ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels to signal and background data, 0 for background,  1 for b-signal\n",
    "# (updated since we might get multiple signals) \n",
    "labeled_background_data = np.append(background_data,np.zeros((background_data.shape[0],1)),axis=1)\n",
    "labeled_b_signal_data = np.append(b_signal_data,np.ones((b_signal_data.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8540cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two data array into one signal array\n",
    "data = np.concatenate((labeled_b_signal_data,labeled_background_data))\n",
    "\n",
    "#and shuffle the data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34eaf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d078bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (2050000, 150)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72830b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for background: 0.51\n",
      "Weight for signal: 20.50\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "total = b_signal_data.shape[0] + background_data.shape[0]\n",
    "weight_for_0 = (1 / background_data.shape[0]) * (total / 2.0)\n",
    "weight_for_1 = (1 / b_signal_data.shape[0]) * (total / 2.0)\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for background: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for signal: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e0e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To categorical as stipulated in example\n",
    "Y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Reshape X to shape (number of jets, 50, 3)\n",
    "X = X.reshape(-1,50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6fe36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2050000/2050000 [01:58<00:00, 17335.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# normalizing jets\n",
    "# copied from example\n",
    "import tqdm\n",
    "for x in tqdm.tqdm(X):\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e18f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing\n",
      "shape of X: (2050000, 50, 3)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print('Finished preprocessing')\n",
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "939de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/val/test split \n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6339cd",
   "metadata": {},
   "source": [
    "# Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4876d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "701/701 [==============================] - 12s 16ms/step - loss: 8.4193 - acc: 0.5062 - val_loss: 0.4630 - val_acc: 0.9512\n",
      "Epoch 2/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.7060 - acc: 0.5300 - val_loss: 1.0496 - val_acc: 0.0427\n",
      "Epoch 3/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.7100 - acc: 0.5132 - val_loss: 0.6790 - val_acc: 0.5931\n",
      "Epoch 4/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6954 - acc: 0.5475 - val_loss: 0.4326 - val_acc: 0.9639\n",
      "Epoch 5/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6970 - acc: 0.5300 - val_loss: 0.8528 - val_acc: 0.0304\n",
      "Epoch 6/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6951 - acc: 0.5330 - val_loss: 0.6051 - val_acc: 0.8895\n",
      "Epoch 7/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6958 - acc: 0.5561 - val_loss: 0.6845 - val_acc: 0.6458\n",
      "Epoch 8/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6905 - acc: 0.5981 - val_loss: 0.6921 - val_acc: 0.6083\n",
      "Epoch 9/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6918 - acc: 0.5967 - val_loss: 0.7165 - val_acc: 0.4427\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 10/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6901 - acc: 0.6213 - val_loss: 0.6995 - val_acc: 0.6490\n",
      "Epoch 11/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6900 - acc: 0.7591 - val_loss: 0.6947 - val_acc: 0.7042\n",
      "Epoch 12/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6892 - acc: 0.8137 - val_loss: 0.7165 - val_acc: 0.5037\n",
      "Epoch 13/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6905 - acc: 0.8136 - val_loss: 0.7009 - val_acc: 0.7920\n",
      "Epoch 14/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6924 - acc: 0.8119 - val_loss: 0.6843 - val_acc: 0.7793\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 15/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6901 - acc: 0.8065 - val_loss: 0.6912 - val_acc: 0.6959\n",
      "Epoch 16/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6931 - acc: 0.7745 - val_loss: 0.6704 - val_acc: 0.9130\n",
      "Epoch 17/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6901 - acc: 0.8759 - val_loss: 0.6793 - val_acc: 0.9006\n",
      "Epoch 18/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6890 - acc: 0.8123 - val_loss: 0.6896 - val_acc: 0.8905\n",
      "Epoch 19/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6886 - acc: 0.8000 - val_loss: 0.6924 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002511886574257803.\n",
      "Epoch 20/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6898 - acc: 0.7889 - val_loss: 0.6782 - val_acc: 0.8579\n",
      "Epoch 21/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6899 - acc: 0.7550 - val_loss: 0.6868 - val_acc: 0.8451\n",
      "Epoch 22/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6892 - acc: 0.7770 - val_loss: 0.6824 - val_acc: 0.8610\n",
      "Epoch 23/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6893 - acc: 0.7711 - val_loss: 0.6653 - val_acc: 0.8375\n",
      "Epoch 24/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6911 - acc: 0.7473 - val_loss: 0.6814 - val_acc: 0.7519\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00015848933651346973.\n",
      "Epoch 25/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6905 - acc: 0.7180 - val_loss: 0.6808 - val_acc: 0.7684\n",
      "Epoch 26/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6903 - acc: 0.7389 - val_loss: 0.6797 - val_acc: 0.7627\n",
      "Epoch 27/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6858 - acc: 0.7485 - val_loss: 0.7079 - val_acc: 0.5817\n",
      "Epoch 28/500\n",
      "701/701 [==============================] - 11s 16ms/step - loss: 0.6892 - acc: 0.7056 - val_loss: 0.7344 - val_acc: 0.4607\n",
      "Epoch 29/500\n",
      "449/701 [==================>...........] - ETA: 3s - loss: 0.6877 - acc: 0.6637"
     ]
    }
   ],
   "source": [
    "# now train the model\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.1**(1/5), patience=5, min_lr=1e-4,\n",
    "                                                verbose=1)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, \n",
    "                                              verbose=1)\n",
    "\n",
    "callbacks = [reduce_lr,early_stop]\n",
    "\n",
    "hist = pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        class_weight=class_weight,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1861",
   "metadata": {},
   "source": [
    "# Analyze the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "531ee50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.4999004380724811\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=10000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ff086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiplicity and mass for comparison\n",
    "masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X])\n",
    "mults = np.asarray([np.count_nonzero(x[:,0]) for x in X])\n",
    "mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses)\n",
    "mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults)\n",
    "\n",
    "# some nicer plot settings \n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "\n",
    "# plot the ROC curves\n",
    "plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN')\n",
    "plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass')\n",
    "plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity')\n",
    "\n",
    "# axes labels\n",
    "plt.xlabel('Quark Jet Efficiency')\n",
    "plt.ylabel('Gluon Jet Rejection')\n",
    "\n",
    "# axes limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# make legend and show plot\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
