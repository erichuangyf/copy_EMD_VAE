{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef50705",
   "metadata": {},
   "source": [
    "# Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a505b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:06:08.800824: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "train, val, test = 0.6, 0.3, 0.1\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 500\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aa5d4",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25276321",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_1_df = \"/global/home/users/yifengh3/VAE/new_data/h_signal.h5\"\n",
    "signal_2_df = \"/global/home/users/yifengh3/VAE/new_data/hv_signal.h5\"\n",
    "signal_1 = pandas.read_hdf(signal_1_df)\n",
    "signal_2 = pandas.read_hdf(signal_2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646d74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal_1 data shape: (34973, 200)\n",
      "signal_2 data shape: (19864, 200)\n"
     ]
    }
   ],
   "source": [
    "print(\"signal_1 data shape: {}\".format(signal_1.shape))\n",
    "print(\"signal_2 data shape: {}\".format(signal_2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e582ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels to signal and background data, 0 for sig1,  1 for sig2\n",
    "# (updated since we might get multiple signals) \n",
    "labeled_sig1 = np.append(signal_1,np.zeros((signal_1.shape[0],1)),axis=1)\n",
    "labeled_sig2 = np.append(signal_2,np.ones((signal_2.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8540cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two data array into one signal array\n",
    "data = np.concatenate((labeled_sig1,labeled_sig2))\n",
    "\n",
    "#and shuffle the data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34eaf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d078bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (54837, 200)\n",
      "shape of Y: (54837,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea34616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for background: 0.78\n",
      "Weight for signal: 1.38\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "total = labeled_sig1.shape[0] + labeled_sig2.shape[0]\n",
    "weight_for_0 = (1 / labeled_sig1.shape[0]) * (total / 2.0)\n",
    "weight_for_1 = (1 / labeled_sig2.shape[0]) * (total / 2.0)\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for background: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for signal: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e0e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To categorical as stipulated in example\n",
    "Y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Reshape X to shape (number of jets, 50, 4)\n",
    "X = X.reshape(-1,50,4)\n",
    "\n",
    "# ignore the pid info\n",
    "X = X[:,:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3e9fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54837, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6fe36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 54837/54837 [00:03<00:00, 17979.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# normalizing jets\n",
    "# copied from example\n",
    "import tqdm\n",
    "for x in tqdm.tqdm(X):\n",
    "    # now add the status bar :)\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3e18f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing\n",
      "shape of X: (54837, 50, 3)\n",
      "shape of Y: (54837,)\n"
     ]
    }
   ],
   "source": [
    "print('Finished preprocessing')\n",
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "939de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/val/test split \n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6339cd",
   "metadata": {},
   "source": [
    "# Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4876d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:06:14.405465: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:06:14.406352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-04-06 16:06:14.431471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-04-06 16:06:14.431493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-06 16:06:14.432795: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-06 16:06:14.432825: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-06 16:06:14.434275: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-06 16:06:14.434475: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-06 16:06:14.435727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-06 16:06:14.436338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-06 16:06:14.439024: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-06 16:06:14.440609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-06 16:06:14.441077: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-06 16:06:14.443579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:41:00.0 name: Quadro RTX 6000 computeCapability: 7.5\n",
      "coreClock: 1.77GHz coreCount: 72 deviceMemorySize: 23.65GiB deviceMemoryBandwidth: 625.94GiB/s\n",
      "2022-04-06 16:06:14.443598: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-06 16:06:14.443616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-04-06 16:06:14.443627: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-04-06 16:06:14.443638: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-04-06 16:06:14.443648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-04-06 16:06:14.443657: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-04-06 16:06:14.443667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-04-06 16:06:14.443677: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-04-06 16:06:14.445074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-04-06 16:06:14.445096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-04-06 16:06:14.974736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-04-06 16:06:14.974784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-04-06 16:06:14.974794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-04-06 16:06:14.977182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 748 MB memory) -> physical GPU (device: 0, name: Quadro RTX 6000, pci bus id: 0000:41:00.0, compute capability: 7.5)\n",
      "2022-04-06 16:06:14.977508: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b559b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:06:15.134571: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-06 16:06:15.135014: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2994530000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " 1/33 [..............................] - ETA: 18s - loss: 232.4277 - acc: 0.3530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-06 16:06:15.538681: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 1s 23ms/step - loss: 90.5649 - acc: 0.5041 - val_loss: 5.7242 - val_acc: 0.3664\n",
      "Epoch 2/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 2.5199 - acc: 0.5317 - val_loss: 0.6083 - val_acc: 0.6919\n",
      "Epoch 3/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.7330 - acc: 0.6360 - val_loss: 0.5967 - val_acc: 0.6804\n",
      "Epoch 4/500\n",
      "33/33 [==============================] - 0s 12ms/step - loss: 0.7899 - acc: 0.6265 - val_loss: 1.0226 - val_acc: 0.5181\n",
      "Epoch 5/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6810 - acc: 0.6506 - val_loss: 0.5702 - val_acc: 0.6998\n",
      "Epoch 6/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6653 - acc: 0.6597 - val_loss: 0.5461 - val_acc: 0.7272\n",
      "Epoch 7/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.6180 - acc: 0.6844 - val_loss: 0.5004 - val_acc: 0.7472\n",
      "Epoch 8/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.5872 - acc: 0.7043 - val_loss: 0.4173 - val_acc: 0.8092\n",
      "Epoch 9/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4873 - acc: 0.7595 - val_loss: 0.8701 - val_acc: 0.6059\n",
      "Epoch 10/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.5339 - acc: 0.7363 - val_loss: 0.4178 - val_acc: 0.8034\n",
      "Epoch 11/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4666 - acc: 0.7719 - val_loss: 0.5376 - val_acc: 0.7336\n",
      "Epoch 12/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.5493 - acc: 0.7436 - val_loss: 0.5258 - val_acc: 0.7466\n",
      "Epoch 13/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.5118 - acc: 0.7538 - val_loss: 0.4643 - val_acc: 0.7732\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 14/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4171 - acc: 0.7998 - val_loss: 0.3984 - val_acc: 0.8169\n",
      "Epoch 15/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3932 - acc: 0.8164 - val_loss: 0.3803 - val_acc: 0.8302\n",
      "Epoch 16/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.4012 - acc: 0.8117 - val_loss: 0.4379 - val_acc: 0.7874\n",
      "Epoch 17/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3954 - acc: 0.8142 - val_loss: 0.3688 - val_acc: 0.8355\n",
      "Epoch 18/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3916 - acc: 0.8224 - val_loss: 0.3686 - val_acc: 0.8350\n",
      "Epoch 19/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3989 - acc: 0.8161 - val_loss: 0.4475 - val_acc: 0.7866\n",
      "Epoch 20/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3770 - acc: 0.8245 - val_loss: 0.4368 - val_acc: 0.7962\n",
      "Epoch 21/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3717 - acc: 0.8304 - val_loss: 0.3535 - val_acc: 0.8444\n",
      "Epoch 22/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.3775 - acc: 0.8273 - val_loss: 0.3745 - val_acc: 0.8313\n",
      "Epoch 23/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3721 - acc: 0.8268 - val_loss: 0.3636 - val_acc: 0.8377\n",
      "Epoch 24/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3830 - acc: 0.8254 - val_loss: 0.4900 - val_acc: 0.7722\n",
      "Epoch 25/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3747 - acc: 0.8268 - val_loss: 0.3653 - val_acc: 0.8366\n",
      "Epoch 26/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3577 - acc: 0.8336 - val_loss: 0.3388 - val_acc: 0.8501\n",
      "Epoch 27/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3705 - acc: 0.8312 - val_loss: 0.3825 - val_acc: 0.8305\n",
      "Epoch 28/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3443 - acc: 0.8457 - val_loss: 0.3405 - val_acc: 0.8528\n",
      "Epoch 29/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3468 - acc: 0.8456 - val_loss: 0.3263 - val_acc: 0.8576\n",
      "Epoch 30/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3727 - acc: 0.8307 - val_loss: 0.3277 - val_acc: 0.8591\n",
      "Epoch 31/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3471 - acc: 0.8460 - val_loss: 0.3226 - val_acc: 0.8610\n",
      "Epoch 32/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3480 - acc: 0.8466 - val_loss: 0.3391 - val_acc: 0.8528\n",
      "Epoch 33/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3267 - acc: 0.8543 - val_loss: 0.3328 - val_acc: 0.8562\n",
      "Epoch 34/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3302 - acc: 0.8531 - val_loss: 0.4147 - val_acc: 0.8091\n",
      "Epoch 35/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3490 - acc: 0.8394 - val_loss: 0.3235 - val_acc: 0.8601\n",
      "Epoch 36/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3348 - acc: 0.8531 - val_loss: 0.3468 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 37/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3101 - acc: 0.8631 - val_loss: 0.3141 - val_acc: 0.8656\n",
      "Epoch 38/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3133 - acc: 0.8630 - val_loss: 0.3263 - val_acc: 0.8587\n",
      "Epoch 39/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3164 - acc: 0.8595 - val_loss: 0.3270 - val_acc: 0.8578\n",
      "Epoch 40/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3063 - acc: 0.8644 - val_loss: 0.3065 - val_acc: 0.8694\n",
      "Epoch 41/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3076 - acc: 0.8631 - val_loss: 0.3079 - val_acc: 0.8691\n",
      "Epoch 42/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3012 - acc: 0.8672 - val_loss: 0.2988 - val_acc: 0.8746\n",
      "Epoch 43/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2884 - acc: 0.8749 - val_loss: 0.2992 - val_acc: 0.8730\n",
      "Epoch 44/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2940 - acc: 0.8713 - val_loss: 0.2979 - val_acc: 0.8744\n",
      "Epoch 45/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2936 - acc: 0.8708 - val_loss: 0.2894 - val_acc: 0.8778\n",
      "Epoch 46/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3050 - acc: 0.8664 - val_loss: 0.3122 - val_acc: 0.8649\n",
      "Epoch 47/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3037 - acc: 0.8661 - val_loss: 0.3517 - val_acc: 0.8473\n",
      "Epoch 48/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3106 - acc: 0.8615 - val_loss: 0.2977 - val_acc: 0.8747\n",
      "Epoch 49/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2888 - acc: 0.8730 - val_loss: 0.4008 - val_acc: 0.8251\n",
      "Epoch 50/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.3060 - acc: 0.8610 - val_loss: 0.3138 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0002511886574257803.\n",
      "Epoch 51/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2891 - acc: 0.8739 - val_loss: 0.3071 - val_acc: 0.8700\n",
      "Epoch 52/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2777 - acc: 0.8801 - val_loss: 0.2886 - val_acc: 0.8787\n",
      "Epoch 53/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2832 - acc: 0.8765 - val_loss: 0.3013 - val_acc: 0.8715\n",
      "Epoch 54/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2773 - acc: 0.8795 - val_loss: 0.2804 - val_acc: 0.8826\n",
      "Epoch 55/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2868 - acc: 0.8739 - val_loss: 0.3222 - val_acc: 0.8634\n",
      "Epoch 56/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2810 - acc: 0.8748 - val_loss: 0.3072 - val_acc: 0.8695\n",
      "Epoch 57/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2785 - acc: 0.8769 - val_loss: 0.3659 - val_acc: 0.8418\n",
      "Epoch 58/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2860 - acc: 0.8737 - val_loss: 0.2873 - val_acc: 0.8779\n",
      "Epoch 59/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2704 - acc: 0.8834 - val_loss: 0.3409 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00015848933651346973.\n",
      "Epoch 60/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2739 - acc: 0.8809 - val_loss: 0.3310 - val_acc: 0.8599\n",
      "Epoch 61/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2762 - acc: 0.8779 - val_loss: 0.2778 - val_acc: 0.8842\n",
      "Epoch 62/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2691 - acc: 0.8851 - val_loss: 0.3007 - val_acc: 0.8718\n",
      "Epoch 63/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2676 - acc: 0.8835 - val_loss: 0.3279 - val_acc: 0.8607\n",
      "Epoch 64/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2691 - acc: 0.8804 - val_loss: 0.2911 - val_acc: 0.8769\n",
      "Epoch 65/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2693 - acc: 0.8792 - val_loss: 0.2908 - val_acc: 0.8773\n",
      "Epoch 66/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2734 - acc: 0.8808 - val_loss: 0.3062 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00010000000838432616.\n",
      "Epoch 67/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2701 - acc: 0.8819 - val_loss: 0.2870 - val_acc: 0.8778\n",
      "Epoch 68/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2600 - acc: 0.8864 - val_loss: 0.2739 - val_acc: 0.8854\n",
      "Epoch 69/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2577 - acc: 0.8898 - val_loss: 0.3080 - val_acc: 0.8703\n",
      "Epoch 70/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2696 - acc: 0.8824 - val_loss: 0.3091 - val_acc: 0.8696\n",
      "Epoch 71/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2612 - acc: 0.8858 - val_loss: 0.3060 - val_acc: 0.8714\n",
      "Epoch 72/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2605 - acc: 0.8872 - val_loss: 0.2890 - val_acc: 0.8792\n",
      "Epoch 73/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2616 - acc: 0.8846 - val_loss: 0.2986 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 6.30957374449059e-05.\n",
      "Epoch 74/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2575 - acc: 0.8859 - val_loss: 0.3010 - val_acc: 0.8745\n",
      "Epoch 75/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2577 - acc: 0.8869 - val_loss: 0.2846 - val_acc: 0.8817\n",
      "Epoch 76/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2560 - acc: 0.8886 - val_loss: 0.2781 - val_acc: 0.8840\n",
      "Epoch 77/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2559 - acc: 0.8888 - val_loss: 0.2863 - val_acc: 0.8808\n",
      "Epoch 78/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2592 - acc: 0.8870 - val_loss: 0.2764 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 3.981071838171537e-05.\n",
      "Epoch 79/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2535 - acc: 0.8928 - val_loss: 0.2721 - val_acc: 0.8860\n",
      "Epoch 80/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2558 - acc: 0.8914 - val_loss: 0.2805 - val_acc: 0.8829\n",
      "Epoch 81/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2563 - acc: 0.8896 - val_loss: 0.2732 - val_acc: 0.8869\n",
      "Epoch 82/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2594 - acc: 0.8877 - val_loss: 0.2880 - val_acc: 0.8790\n",
      "Epoch 83/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2588 - acc: 0.8882 - val_loss: 0.2875 - val_acc: 0.8795\n",
      "Epoch 84/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2530 - acc: 0.8891 - val_loss: 0.2706 - val_acc: 0.8872\n",
      "Epoch 85/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2571 - acc: 0.8888 - val_loss: 0.2714 - val_acc: 0.8879\n",
      "Epoch 86/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2529 - acc: 0.8914 - val_loss: 0.2877 - val_acc: 0.8809\n",
      "Epoch 87/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2500 - acc: 0.8917 - val_loss: 0.2785 - val_acc: 0.8841\n",
      "Epoch 88/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2503 - acc: 0.8902 - val_loss: 0.2751 - val_acc: 0.8869\n",
      "Epoch 89/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2503 - acc: 0.8892 - val_loss: 0.2792 - val_acc: 0.8841\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 2.5118865283496142e-05.\n",
      "Epoch 90/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2510 - acc: 0.8908 - val_loss: 0.2746 - val_acc: 0.8865\n",
      "Epoch 91/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2463 - acc: 0.8936 - val_loss: 0.2724 - val_acc: 0.8866\n",
      "Epoch 92/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2547 - acc: 0.8907 - val_loss: 0.2848 - val_acc: 0.8813\n",
      "Epoch 93/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2499 - acc: 0.8930 - val_loss: 0.2821 - val_acc: 0.8824\n",
      "Epoch 94/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2511 - acc: 0.8910 - val_loss: 0.2842 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.5848932274101303e-05.\n",
      "Epoch 95/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2444 - acc: 0.8951 - val_loss: 0.2759 - val_acc: 0.8862\n",
      "Epoch 96/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2507 - acc: 0.8920 - val_loss: 0.2766 - val_acc: 0.8856\n",
      "Epoch 97/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2497 - acc: 0.8910 - val_loss: 0.2752 - val_acc: 0.8856\n",
      "Epoch 98/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2495 - acc: 0.8917 - val_loss: 0.2825 - val_acc: 0.8825\n",
      "Epoch 99/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2488 - acc: 0.8918 - val_loss: 0.2778 - val_acc: 0.8843\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 1.0000000608891671e-05.\n",
      "Epoch 100/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2454 - acc: 0.8952 - val_loss: 0.2715 - val_acc: 0.8876\n",
      "Epoch 101/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2482 - acc: 0.8933 - val_loss: 0.2702 - val_acc: 0.8882\n",
      "Epoch 102/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2451 - acc: 0.8950 - val_loss: 0.2751 - val_acc: 0.8855\n",
      "Epoch 103/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2500 - acc: 0.8911 - val_loss: 0.2734 - val_acc: 0.8864\n",
      "Epoch 104/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2446 - acc: 0.8953 - val_loss: 0.2833 - val_acc: 0.8837\n",
      "Epoch 105/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2469 - acc: 0.8934 - val_loss: 0.2816 - val_acc: 0.8846\n",
      "Epoch 106/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2453 - acc: 0.8931 - val_loss: 0.2790 - val_acc: 0.8844\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 107/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2493 - acc: 0.8911 - val_loss: 0.2786 - val_acc: 0.8854\n",
      "Epoch 108/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2466 - acc: 0.8929 - val_loss: 0.2731 - val_acc: 0.8870\n",
      "Epoch 109/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2539 - acc: 0.8893 - val_loss: 0.2774 - val_acc: 0.8855\n",
      "Epoch 110/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2470 - acc: 0.8932 - val_loss: 0.2811 - val_acc: 0.8848\n",
      "Epoch 111/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2470 - acc: 0.8927 - val_loss: 0.2690 - val_acc: 0.8886\n",
      "Epoch 112/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2519 - acc: 0.8925 - val_loss: 0.2752 - val_acc: 0.8869\n",
      "Epoch 113/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2481 - acc: 0.8937 - val_loss: 0.2777 - val_acc: 0.8853\n",
      "Epoch 114/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2470 - acc: 0.8935 - val_loss: 0.2789 - val_acc: 0.8854\n",
      "Epoch 115/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2514 - acc: 0.8924 - val_loss: 0.2698 - val_acc: 0.8881\n",
      "Epoch 116/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2480 - acc: 0.8934 - val_loss: 0.2711 - val_acc: 0.8877\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2498 - acc: 0.8908 - val_loss: 0.2737 - val_acc: 0.8872\n",
      "Epoch 118/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2552 - acc: 0.8905 - val_loss: 0.2713 - val_acc: 0.8885\n",
      "Epoch 119/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2492 - acc: 0.8942 - val_loss: 0.2773 - val_acc: 0.8861\n",
      "Epoch 120/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2479 - acc: 0.8931 - val_loss: 0.2780 - val_acc: 0.8857\n",
      "Epoch 121/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2514 - acc: 0.8913 - val_loss: 0.2745 - val_acc: 0.8868\n",
      "Epoch 122/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2475 - acc: 0.8939 - val_loss: 0.2817 - val_acc: 0.8827\n",
      "Epoch 123/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2443 - acc: 0.8941 - val_loss: 0.2742 - val_acc: 0.8866\n",
      "Epoch 124/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2491 - acc: 0.8930 - val_loss: 0.2832 - val_acc: 0.8817\n",
      "Epoch 125/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2445 - acc: 0.8959 - val_loss: 0.2764 - val_acc: 0.8858\n",
      "Epoch 126/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2480 - acc: 0.8925 - val_loss: 0.2760 - val_acc: 0.8852\n",
      "Epoch 127/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2473 - acc: 0.8941 - val_loss: 0.2757 - val_acc: 0.8868\n",
      "Epoch 128/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2460 - acc: 0.8943 - val_loss: 0.2812 - val_acc: 0.8835\n",
      "Epoch 129/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2479 - acc: 0.8943 - val_loss: 0.2754 - val_acc: 0.8861\n",
      "Epoch 130/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2453 - acc: 0.8951 - val_loss: 0.2806 - val_acc: 0.8839\n",
      "Epoch 131/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2472 - acc: 0.8938 - val_loss: 0.2724 - val_acc: 0.8883\n",
      "Epoch 132/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2535 - acc: 0.8897 - val_loss: 0.2815 - val_acc: 0.8841\n",
      "Epoch 133/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2449 - acc: 0.8929 - val_loss: 0.2712 - val_acc: 0.8889\n",
      "Epoch 134/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2437 - acc: 0.8944 - val_loss: 0.2725 - val_acc: 0.8883\n",
      "Epoch 135/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2473 - acc: 0.8935 - val_loss: 0.2854 - val_acc: 0.8812\n",
      "Epoch 136/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2459 - acc: 0.8937 - val_loss: 0.2695 - val_acc: 0.8891\n",
      "Epoch 137/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2491 - acc: 0.8940 - val_loss: 0.2852 - val_acc: 0.8821\n",
      "Epoch 138/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2484 - acc: 0.8901 - val_loss: 0.2748 - val_acc: 0.8858\n",
      "Epoch 139/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2474 - acc: 0.8927 - val_loss: 0.2762 - val_acc: 0.8858\n",
      "Epoch 140/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2471 - acc: 0.8930 - val_loss: 0.2740 - val_acc: 0.8869\n",
      "Epoch 141/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2416 - acc: 0.8963 - val_loss: 0.2693 - val_acc: 0.8899\n",
      "Epoch 142/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2409 - acc: 0.8981 - val_loss: 0.2793 - val_acc: 0.8844\n",
      "Epoch 143/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2455 - acc: 0.8942 - val_loss: 0.2745 - val_acc: 0.8876\n",
      "Epoch 144/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2441 - acc: 0.8951 - val_loss: 0.2700 - val_acc: 0.8885\n",
      "Epoch 145/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2469 - acc: 0.8926 - val_loss: 0.2716 - val_acc: 0.8875\n",
      "Epoch 146/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2521 - acc: 0.8899 - val_loss: 0.2785 - val_acc: 0.8855\n",
      "Epoch 147/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2475 - acc: 0.8913 - val_loss: 0.2721 - val_acc: 0.8888\n",
      "Epoch 148/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2480 - acc: 0.8932 - val_loss: 0.2743 - val_acc: 0.8865\n",
      "Epoch 149/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2483 - acc: 0.8939 - val_loss: 0.2864 - val_acc: 0.8820\n",
      "Epoch 150/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2473 - acc: 0.8913 - val_loss: 0.2854 - val_acc: 0.8821\n",
      "Epoch 151/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2444 - acc: 0.8933 - val_loss: 0.2795 - val_acc: 0.8851\n",
      "Epoch 152/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2454 - acc: 0.8942 - val_loss: 0.2678 - val_acc: 0.8892\n",
      "Epoch 153/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2486 - acc: 0.8937 - val_loss: 0.2667 - val_acc: 0.8902\n",
      "Epoch 154/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2450 - acc: 0.8936 - val_loss: 0.2794 - val_acc: 0.8852\n",
      "Epoch 155/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2461 - acc: 0.8921 - val_loss: 0.2704 - val_acc: 0.8881\n",
      "Epoch 156/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2503 - acc: 0.8930 - val_loss: 0.2726 - val_acc: 0.8884\n",
      "Epoch 157/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2474 - acc: 0.8899 - val_loss: 0.2670 - val_acc: 0.8900\n",
      "Epoch 158/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2453 - acc: 0.8949 - val_loss: 0.2732 - val_acc: 0.8874\n",
      "Epoch 159/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2470 - acc: 0.8940 - val_loss: 0.2725 - val_acc: 0.8872\n",
      "Epoch 160/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2503 - acc: 0.8901 - val_loss: 0.2666 - val_acc: 0.8906\n",
      "Epoch 161/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2430 - acc: 0.8977 - val_loss: 0.2742 - val_acc: 0.8874\n",
      "Epoch 162/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2450 - acc: 0.8947 - val_loss: 0.2782 - val_acc: 0.8847\n",
      "Epoch 163/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2470 - acc: 0.8925 - val_loss: 0.2716 - val_acc: 0.8888\n",
      "Epoch 164/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2454 - acc: 0.8938 - val_loss: 0.2735 - val_acc: 0.8882\n",
      "Epoch 165/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2426 - acc: 0.8954 - val_loss: 0.2701 - val_acc: 0.8888\n",
      "Epoch 166/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2455 - acc: 0.8957 - val_loss: 0.2676 - val_acc: 0.8900\n",
      "Epoch 167/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2451 - acc: 0.8930 - val_loss: 0.2747 - val_acc: 0.8872\n",
      "Epoch 168/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2433 - acc: 0.8961 - val_loss: 0.2754 - val_acc: 0.8868\n",
      "Epoch 169/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2432 - acc: 0.8954 - val_loss: 0.2811 - val_acc: 0.8846\n",
      "Epoch 170/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2449 - acc: 0.8922 - val_loss: 0.2737 - val_acc: 0.8875\n",
      "Epoch 171/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2480 - acc: 0.8928 - val_loss: 0.2675 - val_acc: 0.8891\n",
      "Epoch 172/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2461 - acc: 0.8941 - val_loss: 0.2798 - val_acc: 0.8846\n",
      "Epoch 173/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2487 - acc: 0.8917 - val_loss: 0.2687 - val_acc: 0.8897\n",
      "Epoch 174/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2474 - acc: 0.8944 - val_loss: 0.2724 - val_acc: 0.8877\n",
      "Epoch 175/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2383 - acc: 0.8973 - val_loss: 0.2797 - val_acc: 0.8847\n",
      "Epoch 176/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2461 - acc: 0.8957 - val_loss: 0.2676 - val_acc: 0.8900\n",
      "Epoch 177/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2489 - acc: 0.8931 - val_loss: 0.2755 - val_acc: 0.8872\n",
      "Epoch 178/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2400 - acc: 0.8974 - val_loss: 0.2695 - val_acc: 0.8896\n",
      "Epoch 179/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2418 - acc: 0.8958 - val_loss: 0.2759 - val_acc: 0.8866\n",
      "Epoch 180/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2407 - acc: 0.8957 - val_loss: 0.2714 - val_acc: 0.8896\n",
      "Epoch 181/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2422 - acc: 0.8973 - val_loss: 0.2731 - val_acc: 0.8878\n",
      "Epoch 182/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2396 - acc: 0.8982 - val_loss: 0.2774 - val_acc: 0.8857\n",
      "Epoch 183/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2477 - acc: 0.8924 - val_loss: 0.2676 - val_acc: 0.8909\n",
      "Epoch 184/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2429 - acc: 0.8969 - val_loss: 0.2739 - val_acc: 0.8871\n",
      "Epoch 185/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2454 - acc: 0.8948 - val_loss: 0.2747 - val_acc: 0.8868\n",
      "Epoch 186/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2412 - acc: 0.8975 - val_loss: 0.2815 - val_acc: 0.8830\n",
      "Epoch 187/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2443 - acc: 0.8932 - val_loss: 0.2757 - val_acc: 0.8875\n",
      "Epoch 188/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2452 - acc: 0.8933 - val_loss: 0.2825 - val_acc: 0.8834\n",
      "Epoch 189/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2460 - acc: 0.8917 - val_loss: 0.2711 - val_acc: 0.8889\n",
      "Epoch 190/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2439 - acc: 0.8960 - val_loss: 0.2709 - val_acc: 0.8894\n",
      "Epoch 191/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2438 - acc: 0.8946 - val_loss: 0.2691 - val_acc: 0.8900\n",
      "Epoch 192/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2440 - acc: 0.8942 - val_loss: 0.2675 - val_acc: 0.8902\n",
      "Epoch 193/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2381 - acc: 0.8992 - val_loss: 0.2761 - val_acc: 0.8861\n",
      "Epoch 194/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2423 - acc: 0.8945 - val_loss: 0.2655 - val_acc: 0.8916\n",
      "Epoch 195/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2442 - acc: 0.8946 - val_loss: 0.2669 - val_acc: 0.8899\n",
      "Epoch 196/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2427 - acc: 0.8969 - val_loss: 0.2736 - val_acc: 0.8882\n",
      "Epoch 197/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2413 - acc: 0.8951 - val_loss: 0.2735 - val_acc: 0.8881\n",
      "Epoch 198/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2408 - acc: 0.8968 - val_loss: 0.2910 - val_acc: 0.8798\n",
      "Epoch 199/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2414 - acc: 0.8944 - val_loss: 0.2669 - val_acc: 0.8902\n",
      "Epoch 200/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2431 - acc: 0.8964 - val_loss: 0.2790 - val_acc: 0.8859\n",
      "Epoch 201/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2428 - acc: 0.8948 - val_loss: 0.2733 - val_acc: 0.8865\n",
      "Epoch 202/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2434 - acc: 0.8947 - val_loss: 0.2855 - val_acc: 0.8815\n",
      "Epoch 203/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2473 - acc: 0.8926 - val_loss: 0.2746 - val_acc: 0.8865\n",
      "Epoch 204/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2394 - acc: 0.8963 - val_loss: 0.2741 - val_acc: 0.8861\n",
      "Epoch 205/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2427 - acc: 0.8957 - val_loss: 0.2723 - val_acc: 0.8889\n",
      "Epoch 206/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2444 - acc: 0.8937 - val_loss: 0.2718 - val_acc: 0.8881\n",
      "Epoch 207/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2390 - acc: 0.8977 - val_loss: 0.2675 - val_acc: 0.8894\n",
      "Epoch 208/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2454 - acc: 0.8938 - val_loss: 0.2781 - val_acc: 0.8861\n",
      "Epoch 209/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2444 - acc: 0.8926 - val_loss: 0.2757 - val_acc: 0.8871\n",
      "Epoch 210/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2389 - acc: 0.8967 - val_loss: 0.2679 - val_acc: 0.8900\n",
      "Epoch 211/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2386 - acc: 0.8979 - val_loss: 0.2814 - val_acc: 0.8837\n",
      "Epoch 212/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2447 - acc: 0.8931 - val_loss: 0.2706 - val_acc: 0.8896\n",
      "Epoch 213/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2428 - acc: 0.8949 - val_loss: 0.2829 - val_acc: 0.8844\n",
      "Epoch 214/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2404 - acc: 0.8954 - val_loss: 0.2670 - val_acc: 0.8892\n",
      "Epoch 215/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2425 - acc: 0.8954 - val_loss: 0.2869 - val_acc: 0.8820\n",
      "Epoch 216/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2407 - acc: 0.8943 - val_loss: 0.2694 - val_acc: 0.8902\n",
      "Epoch 217/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2456 - acc: 0.8948 - val_loss: 0.2687 - val_acc: 0.8896\n",
      "Epoch 218/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2396 - acc: 0.8979 - val_loss: 0.2677 - val_acc: 0.8902\n",
      "Epoch 219/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2396 - acc: 0.8966 - val_loss: 0.2777 - val_acc: 0.8872\n",
      "Epoch 220/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2456 - acc: 0.8932 - val_loss: 0.2647 - val_acc: 0.8909\n",
      "Epoch 221/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2439 - acc: 0.8937 - val_loss: 0.2949 - val_acc: 0.8787\n",
      "Epoch 222/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2488 - acc: 0.8927 - val_loss: 0.2651 - val_acc: 0.8917\n",
      "Epoch 223/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2369 - acc: 0.8986 - val_loss: 0.2710 - val_acc: 0.8876\n",
      "Epoch 224/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2435 - acc: 0.8919 - val_loss: 0.2668 - val_acc: 0.8903\n",
      "Epoch 225/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2384 - acc: 0.8977 - val_loss: 0.2654 - val_acc: 0.8911\n",
      "Epoch 226/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2395 - acc: 0.8966 - val_loss: 0.2715 - val_acc: 0.8887\n",
      "Epoch 227/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2385 - acc: 0.8988 - val_loss: 0.2727 - val_acc: 0.8875\n",
      "Epoch 228/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2388 - acc: 0.8954 - val_loss: 0.2805 - val_acc: 0.8852\n",
      "Epoch 229/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2376 - acc: 0.8979 - val_loss: 0.2679 - val_acc: 0.8917\n",
      "Epoch 230/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2395 - acc: 0.8946 - val_loss: 0.2721 - val_acc: 0.8894\n",
      "Epoch 231/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2415 - acc: 0.8981 - val_loss: 0.2765 - val_acc: 0.8853\n",
      "Epoch 232/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2379 - acc: 0.8964 - val_loss: 0.2686 - val_acc: 0.8902\n",
      "Epoch 233/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2336 - acc: 0.8997 - val_loss: 0.2625 - val_acc: 0.8915\n",
      "Epoch 234/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2453 - acc: 0.8948 - val_loss: 0.2703 - val_acc: 0.8899\n",
      "Epoch 235/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2390 - acc: 0.8984 - val_loss: 0.2657 - val_acc: 0.8906\n",
      "Epoch 236/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2400 - acc: 0.8961 - val_loss: 0.2747 - val_acc: 0.8883\n",
      "Epoch 237/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2400 - acc: 0.8971 - val_loss: 0.2852 - val_acc: 0.8834\n",
      "Epoch 238/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2367 - acc: 0.8998 - val_loss: 0.2658 - val_acc: 0.8915\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2412 - acc: 0.8955 - val_loss: 0.2795 - val_acc: 0.8854\n",
      "Epoch 240/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2426 - acc: 0.8942 - val_loss: 0.2758 - val_acc: 0.8856\n",
      "Epoch 241/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2416 - acc: 0.8942 - val_loss: 0.2765 - val_acc: 0.8868\n",
      "Epoch 242/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2376 - acc: 0.8975 - val_loss: 0.2680 - val_acc: 0.8906\n",
      "Epoch 243/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2413 - acc: 0.8960 - val_loss: 0.2795 - val_acc: 0.8864\n",
      "Epoch 244/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2360 - acc: 0.8985 - val_loss: 0.2665 - val_acc: 0.8903\n",
      "Epoch 245/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2376 - acc: 0.8980 - val_loss: 0.2748 - val_acc: 0.8875\n",
      "Epoch 246/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2397 - acc: 0.8952 - val_loss: 0.2759 - val_acc: 0.8866\n",
      "Epoch 247/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2419 - acc: 0.8954 - val_loss: 0.2689 - val_acc: 0.8899\n",
      "Epoch 248/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2418 - acc: 0.8976 - val_loss: 0.2626 - val_acc: 0.8921\n",
      "Epoch 249/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2384 - acc: 0.8989 - val_loss: 0.2695 - val_acc: 0.8898\n",
      "Epoch 250/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2378 - acc: 0.8971 - val_loss: 0.2653 - val_acc: 0.8914\n",
      "Epoch 251/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2355 - acc: 0.8983 - val_loss: 0.2666 - val_acc: 0.8916\n",
      "Epoch 252/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2367 - acc: 0.8976 - val_loss: 0.2662 - val_acc: 0.8921\n",
      "Epoch 253/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2388 - acc: 0.8967 - val_loss: 0.2683 - val_acc: 0.8899\n",
      "Epoch 254/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2362 - acc: 0.8985 - val_loss: 0.2635 - val_acc: 0.8930\n",
      "Epoch 255/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2398 - acc: 0.8964 - val_loss: 0.2757 - val_acc: 0.8876\n",
      "Epoch 256/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2324 - acc: 0.8995 - val_loss: 0.2622 - val_acc: 0.8929\n",
      "Epoch 257/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2404 - acc: 0.8958 - val_loss: 0.2691 - val_acc: 0.8905\n",
      "Epoch 258/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2359 - acc: 0.8993 - val_loss: 0.2755 - val_acc: 0.8873\n",
      "Epoch 259/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2402 - acc: 0.8948 - val_loss: 0.2655 - val_acc: 0.8923\n",
      "Epoch 260/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2299 - acc: 0.9010 - val_loss: 0.2750 - val_acc: 0.8873\n",
      "Epoch 261/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2396 - acc: 0.8941 - val_loss: 0.2610 - val_acc: 0.8918\n",
      "Epoch 262/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2392 - acc: 0.8978 - val_loss: 0.2699 - val_acc: 0.8891\n",
      "Epoch 263/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2407 - acc: 0.8958 - val_loss: 0.2715 - val_acc: 0.8885\n",
      "Epoch 264/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2351 - acc: 0.8979 - val_loss: 0.2624 - val_acc: 0.8912\n",
      "Epoch 265/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2398 - acc: 0.8969 - val_loss: 0.2911 - val_acc: 0.8817\n",
      "Epoch 266/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2344 - acc: 0.8976 - val_loss: 0.2767 - val_acc: 0.8875\n",
      "Epoch 267/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2395 - acc: 0.8953 - val_loss: 0.2623 - val_acc: 0.8917\n",
      "Epoch 268/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2373 - acc: 0.8978 - val_loss: 0.2634 - val_acc: 0.8922\n",
      "Epoch 269/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2362 - acc: 0.8972 - val_loss: 0.2592 - val_acc: 0.8930\n",
      "Epoch 270/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2357 - acc: 0.8988 - val_loss: 0.2598 - val_acc: 0.8931\n",
      "Epoch 271/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2330 - acc: 0.8986 - val_loss: 0.2610 - val_acc: 0.8927\n",
      "Epoch 272/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2384 - acc: 0.8968 - val_loss: 0.2715 - val_acc: 0.8888\n",
      "Epoch 273/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2335 - acc: 0.9004 - val_loss: 0.2715 - val_acc: 0.8891\n",
      "Epoch 274/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2304 - acc: 0.9006 - val_loss: 0.2662 - val_acc: 0.8917\n",
      "Epoch 275/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2322 - acc: 0.9009 - val_loss: 0.2853 - val_acc: 0.8837\n",
      "Epoch 276/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2362 - acc: 0.9003 - val_loss: 0.2732 - val_acc: 0.8880\n",
      "Epoch 277/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2338 - acc: 0.8999 - val_loss: 0.2696 - val_acc: 0.8895\n",
      "Epoch 278/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2318 - acc: 0.8997 - val_loss: 0.2698 - val_acc: 0.8907\n",
      "Epoch 279/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2358 - acc: 0.8982 - val_loss: 0.2701 - val_acc: 0.8886\n",
      "Epoch 280/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2293 - acc: 0.9006 - val_loss: 0.2661 - val_acc: 0.8920\n",
      "Epoch 281/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2336 - acc: 0.9000 - val_loss: 0.2750 - val_acc: 0.8872\n",
      "Epoch 282/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2400 - acc: 0.8968 - val_loss: 0.2750 - val_acc: 0.8876\n",
      "Epoch 283/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2336 - acc: 0.8995 - val_loss: 0.2783 - val_acc: 0.8852\n",
      "Epoch 284/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2371 - acc: 0.8962 - val_loss: 0.2607 - val_acc: 0.8923\n",
      "Epoch 285/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2318 - acc: 0.9026 - val_loss: 0.2720 - val_acc: 0.8874\n",
      "Epoch 286/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2369 - acc: 0.8970 - val_loss: 0.2589 - val_acc: 0.8929\n",
      "Epoch 287/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2343 - acc: 0.8985 - val_loss: 0.2739 - val_acc: 0.8874\n",
      "Epoch 288/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2319 - acc: 0.8983 - val_loss: 0.2555 - val_acc: 0.8930\n",
      "Epoch 289/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2334 - acc: 0.9017 - val_loss: 0.2632 - val_acc: 0.8928\n",
      "Epoch 290/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2390 - acc: 0.8997 - val_loss: 0.2612 - val_acc: 0.8931\n",
      "Epoch 291/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2413 - acc: 0.8976 - val_loss: 0.2677 - val_acc: 0.8894\n",
      "Epoch 292/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2380 - acc: 0.8976 - val_loss: 0.2703 - val_acc: 0.8887\n",
      "Epoch 293/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2320 - acc: 0.9004 - val_loss: 0.2660 - val_acc: 0.8910\n",
      "Epoch 294/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2377 - acc: 0.8965 - val_loss: 0.2764 - val_acc: 0.8867\n",
      "Epoch 295/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2296 - acc: 0.9022 - val_loss: 0.2592 - val_acc: 0.8939\n",
      "Epoch 296/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2337 - acc: 0.9006 - val_loss: 0.2700 - val_acc: 0.8897\n",
      "Epoch 297/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2326 - acc: 0.8996 - val_loss: 0.2779 - val_acc: 0.8862\n",
      "Epoch 298/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2313 - acc: 0.9003 - val_loss: 0.2678 - val_acc: 0.8900\n",
      "Epoch 299/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2327 - acc: 0.9003 - val_loss: 0.2654 - val_acc: 0.8914\n",
      "Epoch 300/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2312 - acc: 0.9015 - val_loss: 0.2710 - val_acc: 0.8888\n",
      "Epoch 301/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2326 - acc: 0.9023 - val_loss: 0.2698 - val_acc: 0.8899\n",
      "Epoch 302/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2334 - acc: 0.8995 - val_loss: 0.2717 - val_acc: 0.8884\n",
      "Epoch 303/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2328 - acc: 0.8999 - val_loss: 0.2900 - val_acc: 0.8821\n",
      "Epoch 304/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2343 - acc: 0.8980 - val_loss: 0.2577 - val_acc: 0.8934\n",
      "Epoch 305/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2364 - acc: 0.8998 - val_loss: 0.2653 - val_acc: 0.8906\n",
      "Epoch 306/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2351 - acc: 0.8984 - val_loss: 0.2678 - val_acc: 0.8901\n",
      "Epoch 307/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2367 - acc: 0.8987 - val_loss: 0.2613 - val_acc: 0.8933\n",
      "Epoch 308/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2339 - acc: 0.8991 - val_loss: 0.2624 - val_acc: 0.8921\n",
      "Epoch 309/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2339 - acc: 0.9001 - val_loss: 0.2637 - val_acc: 0.8927\n",
      "Epoch 310/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - acc: 0.9009 - val_loss: 0.2612 - val_acc: 0.8933\n",
      "Epoch 311/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2328 - acc: 0.8999 - val_loss: 0.2820 - val_acc: 0.8847\n",
      "Epoch 312/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2313 - acc: 0.9007 - val_loss: 0.2563 - val_acc: 0.8945\n",
      "Epoch 313/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2332 - acc: 0.8990 - val_loss: 0.2706 - val_acc: 0.8900\n",
      "Epoch 314/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2298 - acc: 0.9018 - val_loss: 0.2653 - val_acc: 0.8922\n",
      "Epoch 315/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2339 - acc: 0.8992 - val_loss: 0.2735 - val_acc: 0.8883\n",
      "Epoch 316/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - acc: 0.9001 - val_loss: 0.2754 - val_acc: 0.8878\n",
      "Epoch 317/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2315 - acc: 0.9000 - val_loss: 0.2665 - val_acc: 0.8903\n",
      "Epoch 318/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2288 - acc: 0.9009 - val_loss: 0.2553 - val_acc: 0.8948\n",
      "Epoch 319/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2284 - acc: 0.9036 - val_loss: 0.2851 - val_acc: 0.8844\n",
      "Epoch 320/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2333 - acc: 0.8997 - val_loss: 0.2743 - val_acc: 0.8885\n",
      "Epoch 321/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2335 - acc: 0.8973 - val_loss: 0.2639 - val_acc: 0.8921\n",
      "Epoch 322/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2366 - acc: 0.8979 - val_loss: 0.2578 - val_acc: 0.8946\n",
      "Epoch 323/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2325 - acc: 0.8994 - val_loss: 0.2566 - val_acc: 0.8951\n",
      "Epoch 324/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2327 - acc: 0.9013 - val_loss: 0.2682 - val_acc: 0.8908\n",
      "Epoch 325/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2304 - acc: 0.8999 - val_loss: 0.2626 - val_acc: 0.8913\n",
      "Epoch 326/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - acc: 0.9013 - val_loss: 0.2714 - val_acc: 0.8885\n",
      "Epoch 327/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2332 - acc: 0.8987 - val_loss: 0.2635 - val_acc: 0.8918\n",
      "Epoch 328/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2327 - acc: 0.9018 - val_loss: 0.2632 - val_acc: 0.8936\n",
      "Epoch 329/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2307 - acc: 0.9031 - val_loss: 0.2570 - val_acc: 0.8951\n",
      "Epoch 330/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2270 - acc: 0.9037 - val_loss: 0.2578 - val_acc: 0.8950\n",
      "Epoch 331/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2393 - acc: 0.8969 - val_loss: 0.2770 - val_acc: 0.8872\n",
      "Epoch 332/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2334 - acc: 0.9000 - val_loss: 0.2605 - val_acc: 0.8925\n",
      "Epoch 333/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2334 - acc: 0.9004 - val_loss: 0.2687 - val_acc: 0.8899\n",
      "Epoch 334/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2264 - acc: 0.9026 - val_loss: 0.2729 - val_acc: 0.8873\n",
      "Epoch 335/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2299 - acc: 0.8998 - val_loss: 0.2577 - val_acc: 0.8947\n",
      "Epoch 336/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2279 - acc: 0.9017 - val_loss: 0.2687 - val_acc: 0.8895\n",
      "Epoch 337/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2295 - acc: 0.9014 - val_loss: 0.2596 - val_acc: 0.8939\n",
      "Epoch 338/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2322 - acc: 0.9024 - val_loss: 0.2761 - val_acc: 0.8865\n",
      "Epoch 339/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2299 - acc: 0.9012 - val_loss: 0.2602 - val_acc: 0.8939\n",
      "Epoch 340/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2327 - acc: 0.9004 - val_loss: 0.2588 - val_acc: 0.8936\n",
      "Epoch 341/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2341 - acc: 0.9000 - val_loss: 0.2664 - val_acc: 0.8914\n",
      "Epoch 342/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2233 - acc: 0.9036 - val_loss: 0.2815 - val_acc: 0.8860\n",
      "Epoch 343/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2293 - acc: 0.9027 - val_loss: 0.2587 - val_acc: 0.8941\n",
      "Epoch 344/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2339 - acc: 0.9009 - val_loss: 0.2575 - val_acc: 0.8939\n",
      "Epoch 345/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2315 - acc: 0.9004 - val_loss: 0.2648 - val_acc: 0.8907\n",
      "Epoch 346/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2264 - acc: 0.9014 - val_loss: 0.2723 - val_acc: 0.8882\n",
      "Epoch 347/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2325 - acc: 0.9016 - val_loss: 0.2564 - val_acc: 0.8950\n",
      "Epoch 348/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2278 - acc: 0.9049 - val_loss: 0.2678 - val_acc: 0.8911\n",
      "Epoch 349/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2302 - acc: 0.9024 - val_loss: 0.2570 - val_acc: 0.8942\n",
      "Epoch 350/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2332 - acc: 0.8975 - val_loss: 0.2633 - val_acc: 0.8928\n",
      "Epoch 351/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2293 - acc: 0.9030 - val_loss: 0.2547 - val_acc: 0.8945\n",
      "Epoch 352/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2305 - acc: 0.9011 - val_loss: 0.2670 - val_acc: 0.8908\n",
      "Epoch 353/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2304 - acc: 0.9007 - val_loss: 0.2634 - val_acc: 0.8933\n",
      "Epoch 354/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2297 - acc: 0.9036 - val_loss: 0.2576 - val_acc: 0.8942\n",
      "Epoch 355/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2268 - acc: 0.9051 - val_loss: 0.2674 - val_acc: 0.8903\n",
      "Epoch 356/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2280 - acc: 0.9036 - val_loss: 0.2613 - val_acc: 0.8928\n",
      "Epoch 357/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2306 - acc: 0.9005 - val_loss: 0.2613 - val_acc: 0.8932\n",
      "Epoch 358/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2293 - acc: 0.9027 - val_loss: 0.2654 - val_acc: 0.8926\n",
      "Epoch 359/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2338 - acc: 0.9004 - val_loss: 0.2654 - val_acc: 0.8913\n",
      "Epoch 360/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2301 - acc: 0.9017 - val_loss: 0.2631 - val_acc: 0.8927\n",
      "Epoch 361/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2264 - acc: 0.9028 - val_loss: 0.2663 - val_acc: 0.8906\n",
      "Epoch 362/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2338 - acc: 0.8992 - val_loss: 0.2582 - val_acc: 0.8918\n",
      "Epoch 363/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2328 - acc: 0.9013 - val_loss: 0.2601 - val_acc: 0.8937\n",
      "Epoch 364/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2295 - acc: 0.9011 - val_loss: 0.2661 - val_acc: 0.8919\n",
      "Epoch 365/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2307 - acc: 0.9003 - val_loss: 0.2574 - val_acc: 0.8936\n",
      "Epoch 366/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2265 - acc: 0.9048 - val_loss: 0.2569 - val_acc: 0.8947\n",
      "Epoch 367/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2281 - acc: 0.9032 - val_loss: 0.2692 - val_acc: 0.8903\n",
      "Epoch 368/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2320 - acc: 0.9007 - val_loss: 0.2623 - val_acc: 0.8938\n",
      "Epoch 369/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2281 - acc: 0.9025 - val_loss: 0.2538 - val_acc: 0.8958\n",
      "Epoch 370/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2286 - acc: 0.9028 - val_loss: 0.2730 - val_acc: 0.8891\n",
      "Epoch 371/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2265 - acc: 0.9022 - val_loss: 0.2604 - val_acc: 0.8932\n",
      "Epoch 372/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2255 - acc: 0.9026 - val_loss: 0.2654 - val_acc: 0.8923\n",
      "Epoch 373/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2311 - acc: 0.9003 - val_loss: 0.2741 - val_acc: 0.8891\n",
      "Epoch 374/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2268 - acc: 0.9033 - val_loss: 0.2546 - val_acc: 0.8956\n",
      "Epoch 375/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2243 - acc: 0.9064 - val_loss: 0.2601 - val_acc: 0.8944\n",
      "Epoch 376/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2244 - acc: 0.9044 - val_loss: 0.2590 - val_acc: 0.8940\n",
      "Epoch 377/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2201 - acc: 0.9049 - val_loss: 0.2643 - val_acc: 0.8927\n",
      "Epoch 378/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2266 - acc: 0.9038 - val_loss: 0.2680 - val_acc: 0.8913\n",
      "Epoch 379/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2274 - acc: 0.9014 - val_loss: 0.2512 - val_acc: 0.8965\n",
      "Epoch 380/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2322 - acc: 0.9010 - val_loss: 0.2567 - val_acc: 0.8957\n",
      "Epoch 381/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2307 - acc: 0.9011 - val_loss: 0.2881 - val_acc: 0.8827\n",
      "Epoch 382/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2265 - acc: 0.9032 - val_loss: 0.2627 - val_acc: 0.8927\n",
      "Epoch 383/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2228 - acc: 0.9055 - val_loss: 0.2556 - val_acc: 0.8954\n",
      "Epoch 384/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2300 - acc: 0.9022 - val_loss: 0.2647 - val_acc: 0.8916\n",
      "Epoch 385/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2263 - acc: 0.9043 - val_loss: 0.2701 - val_acc: 0.8906\n",
      "Epoch 386/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2312 - acc: 0.9012 - val_loss: 0.2534 - val_acc: 0.8958\n",
      "Epoch 387/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2259 - acc: 0.9031 - val_loss: 0.2630 - val_acc: 0.8927\n",
      "Epoch 388/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2218 - acc: 0.9048 - val_loss: 0.2662 - val_acc: 0.8927\n",
      "Epoch 389/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2245 - acc: 0.9034 - val_loss: 0.2591 - val_acc: 0.8941\n",
      "Epoch 390/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2264 - acc: 0.9027 - val_loss: 0.2559 - val_acc: 0.8955\n",
      "Epoch 391/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2250 - acc: 0.9056 - val_loss: 0.2549 - val_acc: 0.8956\n",
      "Epoch 392/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2213 - acc: 0.9060 - val_loss: 0.2608 - val_acc: 0.8934\n",
      "Epoch 393/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2270 - acc: 0.9016 - val_loss: 0.2595 - val_acc: 0.8932\n",
      "Epoch 394/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2231 - acc: 0.9052 - val_loss: 0.2701 - val_acc: 0.8906\n",
      "Epoch 395/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2262 - acc: 0.9045 - val_loss: 0.2674 - val_acc: 0.8915\n",
      "Epoch 396/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2293 - acc: 0.9022 - val_loss: 0.2567 - val_acc: 0.8959\n",
      "Epoch 397/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2278 - acc: 0.9028 - val_loss: 0.2599 - val_acc: 0.8944\n",
      "Epoch 398/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2207 - acc: 0.9058 - val_loss: 0.2622 - val_acc: 0.8937\n",
      "Epoch 399/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2246 - acc: 0.9064 - val_loss: 0.2614 - val_acc: 0.8947\n",
      "Epoch 400/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2258 - acc: 0.9049 - val_loss: 0.2667 - val_acc: 0.8909\n",
      "Epoch 401/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2256 - acc: 0.9048 - val_loss: 0.2624 - val_acc: 0.8939\n",
      "Epoch 402/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2259 - acc: 0.9041 - val_loss: 0.2689 - val_acc: 0.8917\n",
      "Epoch 403/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2231 - acc: 0.9044 - val_loss: 0.2599 - val_acc: 0.8941\n",
      "Epoch 404/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2245 - acc: 0.9035 - val_loss: 0.2700 - val_acc: 0.8904\n",
      "Epoch 405/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2254 - acc: 0.9042 - val_loss: 0.2650 - val_acc: 0.8922\n",
      "Epoch 406/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2270 - acc: 0.9040 - val_loss: 0.2541 - val_acc: 0.8956\n",
      "Epoch 407/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2249 - acc: 0.9028 - val_loss: 0.2595 - val_acc: 0.8949\n",
      "Epoch 408/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2267 - acc: 0.9046 - val_loss: 0.2605 - val_acc: 0.8942\n",
      "Epoch 409/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2253 - acc: 0.9062 - val_loss: 0.2627 - val_acc: 0.8922\n",
      "Epoch 410/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2245 - acc: 0.9046 - val_loss: 0.2752 - val_acc: 0.8878\n",
      "Epoch 411/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2273 - acc: 0.9013 - val_loss: 0.2577 - val_acc: 0.8948\n",
      "Epoch 412/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2245 - acc: 0.9058 - val_loss: 0.2707 - val_acc: 0.8912\n",
      "Epoch 413/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2229 - acc: 0.9052 - val_loss: 0.2552 - val_acc: 0.8954\n",
      "Epoch 414/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2192 - acc: 0.9073 - val_loss: 0.2566 - val_acc: 0.8947\n",
      "Epoch 415/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2280 - acc: 0.9013 - val_loss: 0.2695 - val_acc: 0.8913\n",
      "Epoch 416/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2275 - acc: 0.9004 - val_loss: 0.2707 - val_acc: 0.8905\n",
      "Epoch 417/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2189 - acc: 0.9058 - val_loss: 0.2613 - val_acc: 0.8943\n",
      "Epoch 418/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2250 - acc: 0.9053 - val_loss: 0.2659 - val_acc: 0.8920\n",
      "Epoch 419/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2231 - acc: 0.9046 - val_loss: 0.2716 - val_acc: 0.8903\n",
      "Epoch 420/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2205 - acc: 0.9073 - val_loss: 0.2655 - val_acc: 0.8921\n",
      "Epoch 421/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2241 - acc: 0.9034 - val_loss: 0.2518 - val_acc: 0.8959\n",
      "Epoch 422/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2237 - acc: 0.9048 - val_loss: 0.2607 - val_acc: 0.8936\n",
      "Epoch 423/500\n",
      "33/33 [==============================] - 0s 10ms/step - loss: 0.2179 - acc: 0.9082 - val_loss: 0.2520 - val_acc: 0.8961\n",
      "Epoch 424/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2251 - acc: 0.9054 - val_loss: 0.2559 - val_acc: 0.8945\n",
      "Epoch 425/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2254 - acc: 0.9024 - val_loss: 0.2686 - val_acc: 0.8922\n",
      "Epoch 426/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2240 - acc: 0.9028 - val_loss: 0.2514 - val_acc: 0.8973\n",
      "Epoch 427/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2251 - acc: 0.9043 - val_loss: 0.2673 - val_acc: 0.8919\n",
      "Epoch 428/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2228 - acc: 0.9071 - val_loss: 0.2735 - val_acc: 0.8892\n",
      "Epoch 429/500\n",
      "33/33 [==============================] - 0s 11ms/step - loss: 0.2250 - acc: 0.9029 - val_loss: 0.2561 - val_acc: 0.8961\n",
      "Epoch 00429: early stopping\n"
     ]
    }
   ],
   "source": [
    "# now train the model\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.1**(1/5), patience=5, min_lr=1e-5,\n",
    "                                                verbose=1)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, \n",
    "                                              verbose=1)\n",
    "\n",
    "callbacks = [reduce_lr,early_stop]\n",
    "\n",
    "hist1 = pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        class_weight=class_weight,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1861",
   "metadata": {},
   "source": [
    "# Analyze the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "531ee50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.9566782348446257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=10000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "403ff086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get multiplicity and mass for comparison\n",
    "masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X])\n",
    "mults = np.asarray([np.count_nonzero(x[:,0]) for x in X])\n",
    "mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses)\n",
    "mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults)\n",
    "\n",
    "# some nicer plot settings \n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "\n",
    "# plot the ROC curves\n",
    "plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN')\n",
    "plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass')\n",
    "plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity')\n",
    "\n",
    "# axes labels\n",
    "plt.xlabel('Quark Jet Efficiency')\n",
    "plt.ylabel('Gluon Jet Rejection')\n",
    "\n",
    "# axes limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# make legend and show plot\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9190f668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(hist1.history[\"val_loss\"],label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcf5a3ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist1.history[\"acc\"],label=\"acc\")\n",
    "plt.plot(hist1.history[\"val_acc\"],label=\"validation acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1abd7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
