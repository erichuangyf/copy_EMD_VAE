{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef50705",
   "metadata": {},
   "source": [
    "# Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a505b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "train, val, test = 0.7, 0.2, 0.1\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 40\n",
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aa5d4",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25276321",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_file = \"/global/home/users/yifengh3/VAE/data/B_signal.h5\"\n",
    "background_file = \"/global/home/users/yifengh3/VAE/data/B_background.h5\"\n",
    "signal_data = pandas.read_hdf(signal_file)\n",
    "background_data = pandas.read_hdf(background_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646d74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal data shape: (50000, 150)\n",
      "backgroubackground_datand data shape: (2000000, 150)\n"
     ]
    }
   ],
   "source": [
    "print(\"signal data shape: {}\".format(signal_data.shape))\n",
    "print(\"backgroubackground_datand data shape: {}\".format(background_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e582ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels to signal and background data, 0 for signal, 1 for background\n",
    "labeled_signal_data = np.append(signal_data,np.zeros((signal_data.shape[0],1)),axis=1)\n",
    "labeled_background_data = np.append(background_data,np.ones((background_data.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8540cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two data array into one signal array\n",
    "data = np.concatenate((labeled_signal_data,labeled_background_data))\n",
    "\n",
    "#and shuffle the data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34eaf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d078bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (2050000, 150)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e0e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To categorical as stipulated in example\n",
    "Y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Reshape X to shape (number of jets, 50, 3)\n",
    "X = X.reshape(-1,50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a6fe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing jets\n",
    "# copied from example\n",
    "# for x in X:\n",
    "#     mask = x[:,0] > 0\n",
    "#     yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "#     x[mask,1:3] -= yphi_avg\n",
    "#     x[mask,0] /= x[:,0].sum()\n",
    "ptsum = np.sum(X[:,:,0],axis=1)\n",
    "X[:,:,0] /= ptsum.reshape((ptsum.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3e18f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing\n",
      "shape of X: (2050000, 50, 3)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print('Finished preprocessing')\n",
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "939de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/val/test split \n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6339cd",
   "metadata": {},
   "source": [
    "# Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4876d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b559b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "718/718 [==============================] - 12s 16ms/step - loss: 9.6023 - acc: 0.9402 - val_loss: 0.1155 - val_acc: 0.9756\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1173 - acc: 0.9758 - val_loss: 0.1152 - val_acc: 0.9756\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1161 - acc: 0.9758 - val_loss: 0.1222 - val_acc: 0.9756\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1168 - acc: 0.9758 - val_loss: 0.1152 - val_acc: 0.9756\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1161 - acc: 0.9757 - val_loss: 0.1161 - val_acc: 0.9756\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1153 - acc: 0.9758 - val_loss: 0.1171 - val_acc: 0.9756\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1156 - acc: 0.9756 - val_loss: 0.1150 - val_acc: 0.9756\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1156 - acc: 0.9756 - val_loss: 0.1151 - val_acc: 0.9756\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1162 - acc: 0.9755 - val_loss: 0.1150 - val_acc: 0.9756\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9757 - val_loss: 0.1163 - val_acc: 0.9756\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1152 - acc: 0.9756 - val_loss: 0.1152 - val_acc: 0.9756\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9756 - val_loss: 0.1148 - val_acc: 0.9756\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1142 - acc: 0.9759 - val_loss: 0.1148 - val_acc: 0.9756\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1160 - val_acc: 0.9756\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1149 - val_acc: 0.9756\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.3025 - acc: 0.9711 - val_loss: 0.1151 - val_acc: 0.9756\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1161 - acc: 0.9754 - val_loss: 0.1159 - val_acc: 0.9756\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1153 - acc: 0.9756 - val_loss: 0.1159 - val_acc: 0.9756\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1148 - acc: 0.9757 - val_loss: 0.1153 - val_acc: 0.9756\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1151 - acc: 0.9756 - val_loss: 0.1147 - val_acc: 0.9756\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1140 - acc: 0.9758 - val_loss: 0.1157 - val_acc: 0.9756\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1147 - acc: 0.9757 - val_loss: 0.1136 - val_acc: 0.9756\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1134 - acc: 0.9755 - val_loss: 0.1118 - val_acc: 0.9756\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1119 - acc: 0.9758 - val_loss: 0.1135 - val_acc: 0.9756\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1119 - acc: 0.9755 - val_loss: 0.1112 - val_acc: 0.9756\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1109 - acc: 0.9758 - val_loss: 0.1176 - val_acc: 0.9756\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1143 - acc: 0.9758 - val_loss: 0.1166 - val_acc: 0.9756\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1127 - acc: 0.9757 - val_loss: 0.1112 - val_acc: 0.9756\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1112 - acc: 0.9757 - val_loss: 0.1114 - val_acc: 0.9756\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1117 - acc: 0.9756 - val_loss: 0.1109 - val_acc: 0.9756\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1112 - acc: 0.9756 - val_loss: 0.1120 - val_acc: 0.9756\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1103 - acc: 0.9758 - val_loss: 0.1109 - val_acc: 0.9756\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1107 - acc: 0.9757 - val_loss: 0.1115 - val_acc: 0.9756\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1110 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9756\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1104 - acc: 0.9758 - val_loss: 0.1114 - val_acc: 0.9756\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1111 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9756\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1107 - acc: 0.9756 - val_loss: 0.1106 - val_acc: 0.9756\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1106 - val_acc: 0.9756\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1106 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9756\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1107 - acc: 0.9756 - val_loss: 0.1109 - val_acc: 0.9756\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3f7028e2b0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1861",
   "metadata": {},
   "source": [
    "# Analyze the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "531ee50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.6311595602850728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "403ff086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get multiplicity and mass for comparison\n",
    "masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X])\n",
    "mults = np.asarray([np.count_nonzero(x[:,0]) for x in X])\n",
    "mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses)\n",
    "mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults)\n",
    "\n",
    "# some nicer plot settings \n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "\n",
    "# plot the ROC curves\n",
    "plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN')\n",
    "plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass')\n",
    "plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity')\n",
    "\n",
    "# axes labels\n",
    "plt.xlabel('Quark Jet Efficiency')\n",
    "plt.ylabel('Gluon Jet Rejection')\n",
    "\n",
    "# axes limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# make legend and show plot\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fa35f",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2a4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (128, 128, 128), (128, 128, 128)\n",
    "num_epoch = 40\n",
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1967d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "718/718 [==============================] - 12s 16ms/step - loss: 12.3076 - acc: 0.9388 - val_loss: 0.1200 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1196 - acc: 0.9754 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1174 - acc: 0.9755 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1167 - acc: 0.9755 - val_loss: 0.1236 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1156 - acc: 0.9757 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1158 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1156 - acc: 0.9754 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1148 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1151 - acc: 0.9755 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1152 - acc: 0.9755 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1161 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9754 - val_loss: 0.1143 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1147 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1153 - acc: 0.9754 - val_loss: 0.1131 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1135 - acc: 0.9758 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1151 - val_acc: 0.9758\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1122 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9754 - val_loss: 0.1124 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1138 - acc: 0.9754 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1115 - acc: 0.9757 - val_loss: 0.1117 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1116 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1121 - acc: 0.9754 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1113 - acc: 0.9755 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1111 - acc: 0.9756 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9757 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1103 - acc: 0.9756 - val_loss: 0.1094 - val_acc: 0.9759\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1095 - acc: 0.9758 - val_loss: 0.1090 - val_acc: 0.9759\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1100 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1098 - acc: 0.9757 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1105 - acc: 0.9754 - val_loss: 0.1093 - val_acc: 0.9758\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1090 - acc: 0.9758 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1086 - acc: 0.9759 - val_loss: 0.1087 - val_acc: 0.9759\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9754 - val_loss: 0.1086 - val_acc: 0.9758\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1084 - acc: 0.9759 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1093 - acc: 0.9756 - val_loss: 0.1083 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1097 - acc: 0.9754 - val_loss: 0.1092 - val_acc: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f5c715c70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "289009d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.6534741416110883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bd4a7",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b5d4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 128)    512         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 128)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 128)    16512       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 128)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    16512       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 128)          16512       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            258         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 83,330\n",
      "Trainable params: 83,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 2.8153 - acc: 0.9517 - val_loss: 0.1155 - val_acc: 0.9758\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1186 - acc: 0.9755 - val_loss: 2.6672 - val_acc: 0.9758\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 1.5392 - acc: 0.9549 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1156 - acc: 0.9754 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1152 - acc: 0.9755 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1146 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1151 - acc: 0.9755 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1144 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1141 - acc: 0.9757 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9756 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1152 - acc: 0.9754 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9755 - val_loss: 0.1116 - val_acc: 0.9758\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1132 - acc: 0.9754 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1123 - acc: 0.9754 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1109 - acc: 0.9757 - val_loss: 0.1107 - val_acc: 0.9758\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1116 - acc: 0.9755 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1118 - acc: 0.9753 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1109 - acc: 0.9755 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1106 - acc: 0.9756 - val_loss: 0.1094 - val_acc: 0.9759\n",
      "Epoch 31/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1111 - acc: 0.9754 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1100 - acc: 0.9757 - val_loss: 0.1090 - val_acc: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1101 - acc: 0.9756 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1091 - acc: 0.9758 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1092 - acc: 0.9758 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1085 - acc: 0.9759 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 37/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1091 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1081 - val_acc: 0.9758\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1093 - acc: 0.9756 - val_loss: 0.1086 - val_acc: 0.9759\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1089 - acc: 0.9757 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1080 - val_acc: 0.9758\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1090 - acc: 0.9756 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1081 - val_acc: 0.9759\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1098 - acc: 0.9753 - val_loss: 0.1082 - val_acc: 0.9758\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1094 - acc: 0.9755 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1093 - acc: 0.9755 - val_loss: 0.1078 - val_acc: 0.9759\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1084 - acc: 0.9758 - val_loss: 0.1079 - val_acc: 0.9759\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1085 - acc: 0.9757 - val_loss: 0.1076 - val_acc: 0.9758\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1081 - acc: 0.9758 - val_loss: 0.1075 - val_acc: 0.9758\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1084 - acc: 0.9756 - val_loss: 0.1077 - val_acc: 0.9759\n",
      "\n",
      "PFN AUC: 0.6645780883918145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (128, 128, 128), (128, 128, 128)\n",
    "num_epoch = 50\n",
    "batch_size = 2000\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a8ce0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.6645780883918145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695397c2",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c58353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "1402/1402 [==============================] - 14s 9ms/step - loss: 5.0168 - acc: 0.9523 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1176 - acc: 0.9755 - val_loss: 0.1176 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1165 - acc: 0.9755 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1162 - acc: 0.9755 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1147 - acc: 0.9757 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1151 - acc: 0.9756 - val_loss: 0.1141 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1159 - acc: 0.9754 - val_loss: 0.1168 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1161 - acc: 0.9753 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1126 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1139 - acc: 0.9756 - val_loss: 0.1125 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1135 - acc: 0.9755 - val_loss: 0.1104 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1118 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1112 - acc: 0.9757 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1114 - acc: 0.9756 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1120 - acc: 0.9753 - val_loss: 0.1103 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1107 - acc: 0.9756 - val_loss: 0.1100 - val_acc: 0.9759\n",
      "Epoch 19/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1106 - acc: 0.9756 - val_loss: 0.1094 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1103 - acc: 0.9756 - val_loss: 0.1091 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1115 - acc: 0.9752 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1106 - acc: 0.9755 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1090 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1107 - acc: 0.9753 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1110 - acc: 0.9753 - val_loss: 0.1100 - val_acc: 0.9759\n",
      "Epoch 26/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1102 - acc: 0.9754 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1089 - acc: 0.9758 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 28/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1095 - acc: 0.9756 - val_loss: 0.1093 - val_acc: 0.9759\n",
      "Epoch 29/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9757 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1096 - acc: 0.9754 - val_loss: 0.1086 - val_acc: 0.9758\n",
      "Epoch 31/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1095 - acc: 0.9755 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 32/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1089 - acc: 0.9757 - val_loss: 0.1081 - val_acc: 0.9759\n",
      "Epoch 33/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1084 - acc: 0.9758 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 34/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1085 - acc: 0.9757 - val_loss: 0.1081 - val_acc: 0.9758\n",
      "Epoch 35/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1081 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1081 - acc: 0.9758 - val_loss: 0.1078 - val_acc: 0.9758\n",
      "Epoch 37/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1082 - acc: 0.9757 - val_loss: 0.1079 - val_acc: 0.9758\n",
      "Epoch 38/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1096 - acc: 0.9753 - val_loss: 0.1077 - val_acc: 0.9758\n",
      "Epoch 39/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1084 - acc: 0.9756 - val_loss: 0.1077 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1086 - acc: 0.9756 - val_loss: 0.1079 - val_acc: 0.9758\n",
      "\n",
      "PFN AUC: 0.6650173740529577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 40\n",
    "batch_size = 1024\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c011d0",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "545af9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1402/1402 [==============================] - 14s 9ms/step - loss: 4.4501 - acc: 0.9497 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 2/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1148 - acc: 0.9758 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 3/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1153 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 4/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1152 - acc: 0.9756 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 5/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1150 - acc: 0.9757 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 6/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1155 - acc: 0.9755 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 7/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 8/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1152 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 9/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1141 - val_acc: 0.9758\n",
      "Epoch 10/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1151 - acc: 0.9755 - val_loss: 0.1153 - val_acc: 0.9758\n",
      "Epoch 11/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 12/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 13/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1155 - acc: 0.9754 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 14/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 15/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 16/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 17/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1143 - acc: 0.9757 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 18/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1147 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 19/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1138 - acc: 0.9758 - val_loss: 0.1123 - val_acc: 0.9758\n",
      "Epoch 20/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1128 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 21/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1120 - acc: 0.9755 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 22/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1102 - acc: 0.9759 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 23/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1119 - acc: 0.9754 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 24/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1116 - acc: 0.9754 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 25/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1107 - acc: 0.9757 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 26/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1113 - acc: 0.9754 - val_loss: 0.1100 - val_acc: 0.9758\n",
      "Epoch 27/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1115 - acc: 0.9753 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 28/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1101 - acc: 0.9757 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 29/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1102 - acc: 0.9756 - val_loss: 0.1106 - val_acc: 0.9758\n",
      "Epoch 30/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1100 - acc: 0.9756 - val_loss: 0.1093 - val_acc: 0.9758\n",
      "Epoch 31/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1094 - acc: 0.9758 - val_loss: 0.1087 - val_acc: 0.9759\n",
      "Epoch 32/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1105 - acc: 0.9755 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 33/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1093 - val_acc: 0.9758\n",
      "Epoch 34/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1094 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 35/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1090 - acc: 0.9758 - val_loss: 0.1090 - val_acc: 0.9759\n",
      "Epoch 36/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1097 - acc: 0.9756 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 37/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1096 - acc: 0.9756 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 38/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 39/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 40/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 41/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9759\n",
      "Epoch 42/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1087 - acc: 0.9758 - val_loss: 0.1086 - val_acc: 0.9758\n",
      "Epoch 43/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1094 - acc: 0.9755 - val_loss: 0.1082 - val_acc: 0.9758\n",
      "Epoch 44/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9755 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 45/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1093 - acc: 0.9755 - val_loss: 0.1083 - val_acc: 0.9758\n",
      "Epoch 46/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1088 - acc: 0.9756 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 47/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1086 - acc: 0.9757 - val_loss: 0.1080 - val_acc: 0.9759\n",
      "Epoch 48/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1090 - acc: 0.9756 - val_loss: 0.1083 - val_acc: 0.9758\n",
      "Epoch 49/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1082 - acc: 0.9757 - val_loss: 0.1079 - val_acc: 0.9759\n",
      "Epoch 50/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1090 - acc: 0.9755 - val_loss: 0.1080 - val_acc: 0.9759\n",
      "\n",
      "PFN AUC: 0.6602831243695352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 50\n",
    "batch_size = 1024\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e3dd0",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f49caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    400         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    25856       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          25700       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 82,458\n",
      "Trainable params: 82,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "2803/2803 [==============================] - 15s 5ms/step - loss: 0.6728 - acc: 0.9676 - val_loss: 0.1155 - val_acc: 0.9758\n",
      "Epoch 2/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1173 - acc: 0.9754 - val_loss: 0.1586 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1172 - acc: 0.9756 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 4/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1162 - acc: 0.9755 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 5/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1147 - acc: 0.9756 - val_loss: 0.1114 - val_acc: 0.9758\n",
      "Epoch 6/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1122 - acc: 0.9758 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 7/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1121 - acc: 0.9756 - val_loss: 0.1109 - val_acc: 0.9758\n",
      "Epoch 8/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1122 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 9/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1116 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 10/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1123 - acc: 0.9754 - val_loss: 0.1107 - val_acc: 0.9758\n",
      "Epoch 11/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1118 - acc: 0.9756 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 12/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1126 - acc: 0.9753 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 13/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1117 - acc: 0.9755 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 14/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1122 - acc: 0.9754 - val_loss: 0.1104 - val_acc: 0.9758\n",
      "Epoch 15/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1111 - acc: 0.9756 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 16/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1109 - acc: 0.9756 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 17/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1113 - acc: 0.9755 - val_loss: 0.1096 - val_acc: 0.9758\n",
      "Epoch 18/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1108 - acc: 0.9757 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 19/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1106 - acc: 0.9757 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 20/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1102 - acc: 0.9757 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "\n",
      "PFN AUC: 0.6281101871145975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (100, 100, 256), (100, 100, 100)\n",
    "num_epoch = 20\n",
    "batch_size = 512\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e6988",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba89f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 512)    131584      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, 512)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 512)          0           mask[0][0]                       \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          131328      sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            1026        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 528,130\n",
      "Trainable params: 528,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "701/701 [==============================] - 16s 22ms/step - loss: 10.0574 - acc: 0.9305 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1160 - acc: 0.9754 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1159 - acc: 0.9754 - val_loss: 0.1146 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1164 - acc: 0.9754 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1142 - acc: 0.9758 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1147 - acc: 0.9757 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1150 - acc: 0.9756 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1140 - acc: 0.9758 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1148 - acc: 0.9754 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1138 - acc: 0.9758 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1139 - acc: 0.9757 - val_loss: 0.1164 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1131 - acc: 0.9756 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1153 - acc: 0.9754 - val_loss: 0.1114 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1130 - acc: 0.9754 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1118 - acc: 0.9755 - val_loss: 0.1111 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1119 - acc: 0.9755 - val_loss: 0.1100 - val_acc: 0.9758\n",
      "Epoch 19/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1125 - acc: 0.9753 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1118 - acc: 0.9755 - val_loss: 0.1113 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1112 - acc: 0.9756 - val_loss: 0.1103 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1114 - acc: 0.9755 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1121 - acc: 0.9753 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1118 - acc: 0.9753 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 26/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1104 - acc: 0.9756 - val_loss: 0.1096 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1100 - acc: 0.9758 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 28/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1097 - acc: 0.9759 - val_loss: 0.1094 - val_acc: 0.9758\n",
      "Epoch 29/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1102 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1114 - acc: 0.9752 - val_loss: 0.1090 - val_acc: 0.9758\n",
      "Epoch 31/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1096 - acc: 0.9757 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 32/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1093 - acc: 0.9758 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 33/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1095 - acc: 0.9757 - val_loss: 0.1095 - val_acc: 0.9759\n",
      "Epoch 34/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1104 - acc: 0.9755 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 35/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1088 - acc: 0.9758 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1094 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 37/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1099 - acc: 0.9755 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 38/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1094 - acc: 0.9756 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 39/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1087 - acc: 0.9758 - val_loss: 0.1088 - val_acc: 0.9759\n",
      "\n",
      "PFN AUC: 0.6545994540481388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (256, 256, 512), (256, 256, 512)\n",
    "num_epoch = 40\n",
    "batch_size = 2048\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bf30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
