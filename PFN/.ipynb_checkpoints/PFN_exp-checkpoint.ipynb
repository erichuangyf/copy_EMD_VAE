{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef50705",
   "metadata": {},
   "source": [
    "# Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a505b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "train, val, test = 0.6, 0.3, 0.1\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 500\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aa5d4",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25276321",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_signal_file = \"/global/home/users/yifengh3/VAE/data/B_signal.h5\"\n",
    "background_file = \"/global/home/users/yifengh3/VAE/data/B_background.h5\"\n",
    "b_signal_data = pandas.read_hdf(b_signal_file)\n",
    "background_data = pandas.read_hdf(background_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646d74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backgroubackground_datand data shape: (2000000, 150)\n",
      "B signal data shape: (50000, 150)\n"
     ]
    }
   ],
   "source": [
    "print(\"backgroubackground_datand data shape: {}\".format(background_data.shape))\n",
    "print(\"B signal data shape: {}\".format(b_signal_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e582ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels to signal and background data, 0 for background,  1 for b-signal\n",
    "# (updated since we might get multiple signals) \n",
    "labeled_background_data = np.append(background_data,np.zeros((background_data.shape[0],1)),axis=1)\n",
    "labeled_b_signal_data = np.append(b_signal_data,np.ones((b_signal_data.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8540cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two data array into one signal array\n",
    "data = np.concatenate((labeled_b_signal_data,labeled_background_data))\n",
    "\n",
    "#and shuffle the data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34eaf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d078bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (2050000, 150)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea34616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for background: 0.51\n",
      "Weight for signal: 20.50\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# The sum of the weights of all examples stays the same.\n",
    "total = b_signal_data.shape[0] + background_data.shape[0]\n",
    "weight_for_0 = (1 / background_data.shape[0]) * (total / 2.0)\n",
    "weight_for_1 = (1 / b_signal_data.shape[0]) * (total / 2.0)\n",
    "\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "print('Weight for background: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for signal: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3e0e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To categorical as stipulated in example\n",
    "Y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Reshape X to shape (number of jets, 50, 3)\n",
    "X = X.reshape(-1,50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a6fe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing jets\n",
    "# copied from example\n",
    "# import tqdm\n",
    "# for x in tqdm.tqdm(X):\n",
    "#     # now add the status bar :)\n",
    "#     mask = x[:,0] > 0\n",
    "#     yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "#     x[mask,1:3] -= yphi_avg\n",
    "#     x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3e18f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing\n",
      "shape of X: (2050000, 50, 3)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print('Finished preprocessing')\n",
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "939de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/val/test split \n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6339cd",
   "metadata": {},
   "source": [
    "# Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4876d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1230/1230 [==============================] - 12s 9ms/step - loss: 8.4695 - acc: 0.5201 - val_loss: 0.7512 - val_acc: 0.4497\n",
      "Epoch 2/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.7094 - acc: 0.5357 - val_loss: 0.6841 - val_acc: 0.5333\n",
      "Epoch 3/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6968 - acc: 0.5424 - val_loss: 0.6545 - val_acc: 0.6387\n",
      "Epoch 4/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6871 - acc: 0.5519 - val_loss: 0.7404 - val_acc: 0.3962\n",
      "Epoch 5/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6793 - acc: 0.5724 - val_loss: 0.6753 - val_acc: 0.5510\n",
      "Epoch 6/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6720 - acc: 0.5951 - val_loss: 0.6673 - val_acc: 0.5575\n",
      "Epoch 7/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6666 - acc: 0.6139 - val_loss: 0.5093 - val_acc: 0.9008\n",
      "Epoch 8/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6612 - acc: 0.6385 - val_loss: 0.6447 - val_acc: 0.6430\n",
      "Epoch 9/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6567 - acc: 0.6324 - val_loss: 0.5313 - val_acc: 0.7296\n",
      "Epoch 10/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6538 - acc: 0.6312 - val_loss: 0.6986 - val_acc: 0.4910\n",
      "Epoch 11/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6506 - acc: 0.6241 - val_loss: 0.6671 - val_acc: 0.6953\n",
      "Epoch 12/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6526 - acc: 0.6455 - val_loss: 0.6179 - val_acc: 0.7906\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.000630957374449059.\n",
      "Epoch 13/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6466 - acc: 0.6652 - val_loss: 0.6744 - val_acc: 0.6331\n",
      "Epoch 14/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6484 - acc: 0.6669 - val_loss: 0.7418 - val_acc: 0.5190\n",
      "Epoch 15/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6451 - acc: 0.6391 - val_loss: 0.5625 - val_acc: 0.7737\n",
      "Epoch 16/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6411 - acc: 0.6798 - val_loss: 0.5781 - val_acc: 0.8091\n",
      "Epoch 17/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6438 - acc: 0.6476 - val_loss: 0.6390 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0003981071838171537.\n",
      "Epoch 18/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6375 - acc: 0.6565 - val_loss: 0.6074 - val_acc: 0.7466\n",
      "Epoch 19/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6393 - acc: 0.6447 - val_loss: 0.6657 - val_acc: 0.6203\n",
      "Epoch 20/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6411 - acc: 0.6609 - val_loss: 0.6721 - val_acc: 0.5788\n",
      "Epoch 21/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6369 - acc: 0.6387 - val_loss: 0.5378 - val_acc: 0.7555\n",
      "Epoch 22/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6415 - acc: 0.6407 - val_loss: 0.6487 - val_acc: 0.6533\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002511886574257803.\n",
      "Epoch 23/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6346 - acc: 0.6378 - val_loss: 0.7277 - val_acc: 0.5214\n",
      "Epoch 24/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6371 - acc: 0.6493 - val_loss: 0.6241 - val_acc: 0.6814\n",
      "Epoch 25/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6335 - acc: 0.6505 - val_loss: 0.6215 - val_acc: 0.6924\n",
      "Epoch 26/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6358 - acc: 0.6488 - val_loss: 0.7032 - val_acc: 0.5351\n",
      "Epoch 27/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6328 - acc: 0.6419 - val_loss: 0.6470 - val_acc: 0.6515\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00015848933651346973.\n",
      "Epoch 28/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6315 - acc: 0.6475 - val_loss: 0.6481 - val_acc: 0.5988\n",
      "Epoch 29/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6306 - acc: 0.6506 - val_loss: 0.6695 - val_acc: 0.5731\n",
      "Epoch 30/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6325 - acc: 0.6467 - val_loss: 0.6494 - val_acc: 0.6094\n",
      "Epoch 31/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6303 - acc: 0.6448 - val_loss: 0.5906 - val_acc: 0.7220\n",
      "Epoch 32/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6314 - acc: 0.6555 - val_loss: 0.6444 - val_acc: 0.6378\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00010000000838432616.\n",
      "Epoch 33/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6292 - acc: 0.6603 - val_loss: 0.6422 - val_acc: 0.6214\n",
      "Epoch 34/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6266 - acc: 0.6475 - val_loss: 0.6258 - val_acc: 0.6462\n",
      "Epoch 35/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6243 - acc: 0.6590 - val_loss: 0.6044 - val_acc: 0.6849\n",
      "Epoch 36/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6293 - acc: 0.6618 - val_loss: 0.6289 - val_acc: 0.6604\n",
      "Epoch 37/500\n",
      "1230/1230 [==============================] - 11s 9ms/step - loss: 0.6276 - acc: 0.6568 - val_loss: 0.5675 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.30957374449059e-05.\n",
      "Epoch 38/500\n",
      " 492/1230 [===========>..................] - ETA: 5s - loss: 0.6311 - acc: 0.6635"
     ]
    }
   ],
   "source": [
    "# now train the model\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', \n",
    "                              factor=0.1**(1/5), patience=5, min_lr=1e-5,\n",
    "                                                verbose=1)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=40, \n",
    "                                              verbose=1)\n",
    "\n",
    "callbacks = [reduce_lr,early_stop]\n",
    "\n",
    "hist1 = pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        class_weight=class_weight,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1861",
   "metadata": {},
   "source": [
    "# Analyze the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ee50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=10000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ff086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get multiplicity and mass for comparison\n",
    "masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X])\n",
    "mults = np.asarray([np.count_nonzero(x[:,0]) for x in X])\n",
    "mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses)\n",
    "mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults)\n",
    "\n",
    "# some nicer plot settings \n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "\n",
    "# plot the ROC curves\n",
    "plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN')\n",
    "plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass')\n",
    "plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity')\n",
    "\n",
    "# axes labels\n",
    "plt.xlabel('Quark Jet Efficiency')\n",
    "plt.ylabel('Gluon Jet Rejection')\n",
    "\n",
    "# axes limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# make legend and show plot\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist1.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(hist1.history[\"val_loss\"],label=\"validation loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist1.history[\"acc\"],label=\"acc\")\n",
    "plt.plot(hist1.history[\"val_acc\"],label=\"validation acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ba574f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
