{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef50705",
   "metadata": {},
   "source": [
    "# Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05a505b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# standard library imports\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# standard numerical library imports\n",
    "import numpy as np\n",
    "\n",
    "# energyflow imports\n",
    "import energyflow as ef\n",
    "from energyflow.archs import PFN\n",
    "from energyflow.datasets import qg_jets\n",
    "from energyflow.utils import data_split, remap_pids, to_categorical\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pandas\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45667e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "train, val, test = 0.7, 0.2, 0.1\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 40\n",
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5aa5d4",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25276321",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_file = \"/global/home/users/yifengh3/VAE/data/B_signal.h5\"\n",
    "background_file = \"/global/home/users/yifengh3/VAE/data/B_background.h5\"\n",
    "signal_data = pandas.read_hdf(signal_file)\n",
    "background_data = pandas.read_hdf(background_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "646d74c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signal data shape: (50000, 150)\n",
      "backgroubackground_datand data shape: (2000000, 150)\n"
     ]
    }
   ],
   "source": [
    "print(\"signal data shape: {}\".format(signal_data.shape))\n",
    "print(\"backgroubackground_datand data shape: {}\".format(background_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e582ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign labels to signal and background data, 0 for signal, 1 for background\n",
    "labeled_signal_data = np.append(signal_data,np.zeros((signal_data.shape[0],1)),axis=1)\n",
    "labeled_background_data = np.append(background_data,np.ones((background_data.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8540cc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix two data array into one signal array\n",
    "data = np.concatenate((labeled_signal_data,labeled_background_data))\n",
    "\n",
    "#and shuffle the data\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34eaf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:-1]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d078bbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (2050000, 150)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e0e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To categorical as stipulated in example\n",
    "Y = to_categorical(y, num_classes=2)\n",
    "\n",
    "# Reshape X to shape (number of jets, 50, 3)\n",
    "X = X.reshape(-1,50,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a6fe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing jets\n",
    "# copied from example\n",
    "for x in X:\n",
    "    mask = x[:,0] > 0\n",
    "    yphi_avg = np.average(x[mask,1:3], weights=x[mask,0], axis=0)\n",
    "    x[mask,1:3] -= yphi_avg\n",
    "    x[mask,0] /= x[:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3e18f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing\n",
      "shape of X: (2050000, 50, 3)\n",
      "shape of Y: (2050000,)\n"
     ]
    }
   ],
   "source": [
    "print('Finished preprocessing')\n",
    "print(\"shape of X: {}\".format(X.shape))\n",
    "print(\"shape of Y: {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "939de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do train/val/test split \n",
    "(X_train, X_val, X_test,\n",
    " Y_train, Y_val, Y_test) = data_split(X, Y, val=val, test=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6339cd",
   "metadata": {},
   "source": [
    "# Build and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4876d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b559b182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "718/718 [==============================] - 12s 16ms/step - loss: 4.0497 - acc: 0.9444 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1159 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9757 - val_loss: 0.1198 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1154 - acc: 0.9756 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1160 - acc: 0.9754 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1145 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1143 - acc: 0.9757 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1147 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1147 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.3323 - acc: 0.9707 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1132 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1146 - acc: 0.9755 - val_loss: 0.1130 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1143 - acc: 0.9756 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1146 - acc: 0.9755 - val_loss: 0.1131 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1136 - acc: 0.9757 - val_loss: 0.1123 - val_acc: 0.9758\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1142 - acc: 0.9753 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1127 - acc: 0.9755 - val_loss: 0.1119 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1118 - acc: 0.9756 - val_loss: 0.1111 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1116 - acc: 0.9756 - val_loss: 0.1109 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1116 - acc: 0.9756 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1107 - acc: 0.9757 - val_loss: 0.1109 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9757 - val_loss: 0.1106 - val_acc: 0.9758\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1103 - acc: 0.9757 - val_loss: 0.1106 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1113 - acc: 0.9755 - val_loss: 0.1092 - val_acc: 0.9759\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1109 - acc: 0.9755 - val_loss: 0.1096 - val_acc: 0.9758\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1099 - acc: 0.9757 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9757 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1104 - acc: 0.9755 - val_loss: 0.1094 - val_acc: 0.9759\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1094 - acc: 0.9758 - val_loss: 0.1089 - val_acc: 0.9759\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1090 - val_acc: 0.9758\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1098 - acc: 0.9756 - val_loss: 0.1086 - val_acc: 0.9759\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9754 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1107 - acc: 0.9753 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1094 - acc: 0.9756 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1093 - acc: 0.9756 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1087 - acc: 0.9757 - val_loss: 0.1096 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1093 - acc: 0.9756 - val_loss: 0.1080 - val_acc: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1ff80a3430>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1861",
   "metadata": {},
   "source": [
    "# Analyze the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "531ee50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.6612140949097215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "403ff086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get multiplicity and mass for comparison\n",
    "masses = np.asarray([ef.ms_from_p4s(ef.p4s_from_ptyphims(x).sum(axis=0)) for x in X])\n",
    "mults = np.asarray([np.count_nonzero(x[:,0]) for x in X])\n",
    "mass_fp, mass_tp, threshs = roc_curve(Y[:,1], -masses)\n",
    "mult_fp, mult_tp, threshs = roc_curve(Y[:,1], -mults)\n",
    "\n",
    "# some nicer plot settings \n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "\n",
    "# plot the ROC curves\n",
    "plt.plot(pfn_tp, 1-pfn_fp, '-', color='black', label='PFN')\n",
    "plt.plot(mass_tp, 1-mass_fp, '-', color='blue', label='Jet Mass')\n",
    "plt.plot(mult_tp, 1-mult_fp, '-', color='red', label='Multiplicity')\n",
    "\n",
    "# axes labels\n",
    "plt.xlabel('Quark Jet Efficiency')\n",
    "plt.ylabel('Gluon Jet Rejection')\n",
    "\n",
    "# axes limits\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# make legend and show plot\n",
    "plt.legend(loc='lower left', frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80fa35f",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f2a4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (128, 128, 128), (128, 128, 128)\n",
    "num_epoch = 40\n",
    "batch_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd1967d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "718/718 [==============================] - 12s 16ms/step - loss: 12.3076 - acc: 0.9388 - val_loss: 0.1200 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1196 - acc: 0.9754 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1174 - acc: 0.9755 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1167 - acc: 0.9755 - val_loss: 0.1236 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1156 - acc: 0.9757 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1158 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1156 - acc: 0.9754 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1148 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1151 - acc: 0.9755 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1152 - acc: 0.9755 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1161 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1155 - acc: 0.9754 - val_loss: 0.1143 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1147 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1153 - acc: 0.9754 - val_loss: 0.1131 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1135 - acc: 0.9758 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1151 - val_acc: 0.9758\n",
      "Epoch 19/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1122 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1150 - acc: 0.9754 - val_loss: 0.1124 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1138 - acc: 0.9754 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1115 - acc: 0.9757 - val_loss: 0.1117 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1116 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1121 - acc: 0.9754 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1113 - acc: 0.9755 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 26/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1111 - acc: 0.9756 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 28/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 29/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9757 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1103 - acc: 0.9756 - val_loss: 0.1094 - val_acc: 0.9759\n",
      "Epoch 31/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1095 - acc: 0.9758 - val_loss: 0.1090 - val_acc: 0.9759\n",
      "Epoch 32/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1100 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 33/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1098 - acc: 0.9757 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 34/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1105 - acc: 0.9754 - val_loss: 0.1093 - val_acc: 0.9758\n",
      "Epoch 35/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1090 - acc: 0.9758 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1086 - acc: 0.9759 - val_loss: 0.1087 - val_acc: 0.9759\n",
      "Epoch 37/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1102 - acc: 0.9754 - val_loss: 0.1086 - val_acc: 0.9758\n",
      "Epoch 38/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1084 - acc: 0.9759 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 39/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1093 - acc: 0.9756 - val_loss: 0.1083 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "718/718 [==============================] - 11s 15ms/step - loss: 0.1097 - acc: 0.9754 - val_loss: 0.1092 - val_acc: 0.9758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1f5c715c70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "289009d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.6534741416110883\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24bd4a7",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66b5d4c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 128)    512         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 128)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 128)    16512       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 128)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 128)    16512       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, 128)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 128)          0           mask[0][0]                       \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 128)          16512       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          16512       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            258         activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 83,330\n",
      "Trainable params: 83,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 2.8153 - acc: 0.9517 - val_loss: 0.1155 - val_acc: 0.9758\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1186 - acc: 0.9755 - val_loss: 2.6672 - val_acc: 0.9758\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 1.5392 - acc: 0.9549 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1156 - acc: 0.9754 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1152 - acc: 0.9755 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1157 - acc: 0.9754 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1146 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1151 - acc: 0.9755 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1144 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1141 - acc: 0.9757 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9756 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1152 - acc: 0.9754 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1145 - acc: 0.9755 - val_loss: 0.1116 - val_acc: 0.9758\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1132 - acc: 0.9754 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1123 - acc: 0.9754 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1109 - acc: 0.9757 - val_loss: 0.1107 - val_acc: 0.9758\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1116 - acc: 0.9755 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1118 - acc: 0.9753 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1109 - acc: 0.9755 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1106 - acc: 0.9756 - val_loss: 0.1094 - val_acc: 0.9759\n",
      "Epoch 31/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1111 - acc: 0.9754 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1100 - acc: 0.9757 - val_loss: 0.1090 - val_acc: 0.9758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1101 - acc: 0.9756 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1091 - acc: 0.9758 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1092 - acc: 0.9758 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1085 - acc: 0.9759 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 37/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1091 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1081 - val_acc: 0.9758\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1093 - acc: 0.9756 - val_loss: 0.1086 - val_acc: 0.9759\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1089 - acc: 0.9757 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1080 - val_acc: 0.9758\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1090 - acc: 0.9756 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1081 - val_acc: 0.9759\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1098 - acc: 0.9753 - val_loss: 0.1082 - val_acc: 0.9758\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1094 - acc: 0.9755 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1093 - acc: 0.9755 - val_loss: 0.1078 - val_acc: 0.9759\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1084 - acc: 0.9758 - val_loss: 0.1079 - val_acc: 0.9759\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1085 - acc: 0.9757 - val_loss: 0.1076 - val_acc: 0.9758\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1081 - acc: 0.9758 - val_loss: 0.1075 - val_acc: 0.9758\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 6s 8ms/step - loss: 0.1084 - acc: 0.9756 - val_loss: 0.1077 - val_acc: 0.9759\n",
      "\n",
      "PFN AUC: 0.6645780883918145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (128, 128, 128), (128, 128, 128)\n",
    "num_epoch = 50\n",
    "batch_size = 2000\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a8ce0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PFN AUC: 0.6645780883918145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695397c2",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c58353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "1402/1402 [==============================] - 14s 9ms/step - loss: 5.0168 - acc: 0.9523 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1176 - acc: 0.9755 - val_loss: 0.1176 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1165 - acc: 0.9755 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1162 - acc: 0.9755 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1147 - acc: 0.9757 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1151 - acc: 0.9756 - val_loss: 0.1141 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1159 - acc: 0.9754 - val_loss: 0.1168 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1161 - acc: 0.9753 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1150 - acc: 0.9755 - val_loss: 0.1126 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1139 - acc: 0.9756 - val_loss: 0.1125 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1135 - acc: 0.9755 - val_loss: 0.1104 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1118 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1112 - acc: 0.9757 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1114 - acc: 0.9756 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1120 - acc: 0.9753 - val_loss: 0.1103 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1107 - acc: 0.9756 - val_loss: 0.1100 - val_acc: 0.9759\n",
      "Epoch 19/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1106 - acc: 0.9756 - val_loss: 0.1094 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1103 - acc: 0.9756 - val_loss: 0.1091 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1115 - acc: 0.9752 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1106 - acc: 0.9755 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1090 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1107 - acc: 0.9753 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1110 - acc: 0.9753 - val_loss: 0.1100 - val_acc: 0.9759\n",
      "Epoch 26/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1102 - acc: 0.9754 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1089 - acc: 0.9758 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 28/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1095 - acc: 0.9756 - val_loss: 0.1093 - val_acc: 0.9759\n",
      "Epoch 29/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9757 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1096 - acc: 0.9754 - val_loss: 0.1086 - val_acc: 0.9758\n",
      "Epoch 31/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1095 - acc: 0.9755 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 32/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1089 - acc: 0.9757 - val_loss: 0.1081 - val_acc: 0.9759\n",
      "Epoch 33/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1084 - acc: 0.9758 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 34/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1085 - acc: 0.9757 - val_loss: 0.1081 - val_acc: 0.9758\n",
      "Epoch 35/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1081 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1081 - acc: 0.9758 - val_loss: 0.1078 - val_acc: 0.9758\n",
      "Epoch 37/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1082 - acc: 0.9757 - val_loss: 0.1079 - val_acc: 0.9758\n",
      "Epoch 38/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1096 - acc: 0.9753 - val_loss: 0.1077 - val_acc: 0.9758\n",
      "Epoch 39/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1084 - acc: 0.9756 - val_loss: 0.1077 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1086 - acc: 0.9756 - val_loss: 0.1079 - val_acc: 0.9758\n",
      "\n",
      "PFN AUC: 0.6650173740529577\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 40\n",
    "batch_size = 1024\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c011d0",
   "metadata": {},
   "source": [
    "# Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "545af9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    65792       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          65792       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            514         activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 330,498\n",
      "Trainable params: 330,498\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1402/1402 [==============================] - 14s 9ms/step - loss: 4.4501 - acc: 0.9497 - val_loss: 0.1137 - val_acc: 0.9758\n",
      "Epoch 2/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1148 - acc: 0.9758 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 3/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1153 - acc: 0.9756 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 4/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1152 - acc: 0.9756 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 5/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1150 - acc: 0.9757 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 6/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1155 - acc: 0.9755 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 7/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 8/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1152 - acc: 0.9756 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 9/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1141 - val_acc: 0.9758\n",
      "Epoch 10/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1151 - acc: 0.9755 - val_loss: 0.1153 - val_acc: 0.9758\n",
      "Epoch 11/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9756 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 12/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1144 - acc: 0.9757 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 13/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1155 - acc: 0.9754 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 14/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 15/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 16/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1149 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 17/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1143 - acc: 0.9757 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 18/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1147 - acc: 0.9755 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 19/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1138 - acc: 0.9758 - val_loss: 0.1123 - val_acc: 0.9758\n",
      "Epoch 20/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1128 - acc: 0.9756 - val_loss: 0.1108 - val_acc: 0.9758\n",
      "Epoch 21/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1120 - acc: 0.9755 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 22/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1102 - acc: 0.9759 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 23/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1119 - acc: 0.9754 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 24/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1116 - acc: 0.9754 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 25/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1107 - acc: 0.9757 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 26/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1113 - acc: 0.9754 - val_loss: 0.1100 - val_acc: 0.9758\n",
      "Epoch 27/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1115 - acc: 0.9753 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 28/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1101 - acc: 0.9757 - val_loss: 0.1095 - val_acc: 0.9758\n",
      "Epoch 29/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1102 - acc: 0.9756 - val_loss: 0.1106 - val_acc: 0.9758\n",
      "Epoch 30/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1100 - acc: 0.9756 - val_loss: 0.1093 - val_acc: 0.9758\n",
      "Epoch 31/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1094 - acc: 0.9758 - val_loss: 0.1087 - val_acc: 0.9759\n",
      "Epoch 32/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1105 - acc: 0.9755 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 33/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1101 - acc: 0.9755 - val_loss: 0.1093 - val_acc: 0.9758\n",
      "Epoch 34/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1094 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 35/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1090 - acc: 0.9758 - val_loss: 0.1090 - val_acc: 0.9759\n",
      "Epoch 36/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1097 - acc: 0.9756 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 37/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1096 - acc: 0.9756 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 38/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 39/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1084 - val_acc: 0.9758\n",
      "Epoch 40/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1092 - acc: 0.9756 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 41/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9759\n",
      "Epoch 42/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1087 - acc: 0.9758 - val_loss: 0.1086 - val_acc: 0.9758\n",
      "Epoch 43/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1094 - acc: 0.9755 - val_loss: 0.1082 - val_acc: 0.9758\n",
      "Epoch 44/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1091 - acc: 0.9755 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 45/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1093 - acc: 0.9755 - val_loss: 0.1083 - val_acc: 0.9758\n",
      "Epoch 46/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1088 - acc: 0.9756 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 47/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1086 - acc: 0.9757 - val_loss: 0.1080 - val_acc: 0.9759\n",
      "Epoch 48/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1090 - acc: 0.9756 - val_loss: 0.1083 - val_acc: 0.9758\n",
      "Epoch 49/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1082 - acc: 0.9757 - val_loss: 0.1079 - val_acc: 0.9759\n",
      "Epoch 50/50\n",
      "1402/1402 [==============================] - 13s 9ms/step - loss: 0.1090 - acc: 0.9755 - val_loss: 0.1080 - val_acc: 0.9759\n",
      "\n",
      "PFN AUC: 0.6602831243695352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (256, 256, 256), (256, 256, 256)\n",
    "num_epoch = 50\n",
    "batch_size = 1024\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561e3dd0",
   "metadata": {},
   "source": [
    "# Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f49caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 100)    400         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, None, 100)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 100)    10100       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, None, 100)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 256)    25856       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, None, 256)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 256)          0           mask[0][0]                       \n",
      "                                                                 activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 100)          25700       sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 100)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          10100       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          10100       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 100)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 82,458\n",
      "Trainable params: 82,458\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "2803/2803 [==============================] - 15s 5ms/step - loss: 0.6728 - acc: 0.9676 - val_loss: 0.1155 - val_acc: 0.9758\n",
      "Epoch 2/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1173 - acc: 0.9754 - val_loss: 0.1586 - val_acc: 0.9758\n",
      "Epoch 3/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1172 - acc: 0.9756 - val_loss: 0.1147 - val_acc: 0.9758\n",
      "Epoch 4/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1162 - acc: 0.9755 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 5/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1147 - acc: 0.9756 - val_loss: 0.1114 - val_acc: 0.9758\n",
      "Epoch 6/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1122 - acc: 0.9758 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 7/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1121 - acc: 0.9756 - val_loss: 0.1109 - val_acc: 0.9758\n",
      "Epoch 8/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1122 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 9/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1116 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 10/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1123 - acc: 0.9754 - val_loss: 0.1107 - val_acc: 0.9758\n",
      "Epoch 11/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1118 - acc: 0.9756 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 12/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1126 - acc: 0.9753 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 13/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1117 - acc: 0.9755 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 14/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1122 - acc: 0.9754 - val_loss: 0.1104 - val_acc: 0.9758\n",
      "Epoch 15/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1111 - acc: 0.9756 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 16/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1109 - acc: 0.9756 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 17/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1113 - acc: 0.9755 - val_loss: 0.1096 - val_acc: 0.9758\n",
      "Epoch 18/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1108 - acc: 0.9757 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 19/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1106 - acc: 0.9757 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 20/20\n",
      "2803/2803 [==============================] - 14s 5ms/step - loss: 0.1102 - acc: 0.9757 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "\n",
      "PFN AUC: 0.6281101871145975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (100, 100, 256), (100, 100, 100)\n",
    "num_epoch = 20\n",
    "batch_size = 512\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e6988",
   "metadata": {},
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba89f435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, None, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tdist_0 (TimeDistributed)       (None, None, 256)    1024        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, None, 256)    0           tdist_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_1 (TimeDistributed)       (None, None, 256)    65792       activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, None, 256)    0           tdist_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tdist_2 (TimeDistributed)       (None, None, 512)    131584      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "mask (Lambda)                   (None, None)         0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, None, 512)    0           tdist_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sum (Dot)                       (None, 512)          0           mask[0][0]                       \n",
      "                                                                 activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_0 (Dense)                 (None, 256)          131328      sum[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 256)          0           dense_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            1026        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 2)            0           output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 528,130\n",
      "Trainable params: 528,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/40\n",
      "701/701 [==============================] - 16s 22ms/step - loss: 10.0574 - acc: 0.9305 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 2/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1160 - acc: 0.9754 - val_loss: 0.1139 - val_acc: 0.9758\n",
      "Epoch 3/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1159 - acc: 0.9754 - val_loss: 0.1146 - val_acc: 0.9758\n",
      "Epoch 4/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1164 - acc: 0.9754 - val_loss: 0.1136 - val_acc: 0.9758\n",
      "Epoch 5/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1142 - acc: 0.9758 - val_loss: 0.1140 - val_acc: 0.9758\n",
      "Epoch 6/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1146 - acc: 0.9757 - val_loss: 0.1142 - val_acc: 0.9758\n",
      "Epoch 7/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1147 - acc: 0.9757 - val_loss: 0.1134 - val_acc: 0.9758\n",
      "Epoch 8/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1150 - acc: 0.9756 - val_loss: 0.1138 - val_acc: 0.9758\n",
      "Epoch 9/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1153 - acc: 0.9755 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 10/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1140 - acc: 0.9758 - val_loss: 0.1133 - val_acc: 0.9758\n",
      "Epoch 11/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1148 - acc: 0.9754 - val_loss: 0.1135 - val_acc: 0.9758\n",
      "Epoch 12/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1138 - acc: 0.9758 - val_loss: 0.1144 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1139 - acc: 0.9757 - val_loss: 0.1164 - val_acc: 0.9758\n",
      "Epoch 14/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1131 - acc: 0.9756 - val_loss: 0.1112 - val_acc: 0.9758\n",
      "Epoch 15/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1153 - acc: 0.9754 - val_loss: 0.1114 - val_acc: 0.9758\n",
      "Epoch 16/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1130 - acc: 0.9754 - val_loss: 0.1102 - val_acc: 0.9758\n",
      "Epoch 17/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1118 - acc: 0.9755 - val_loss: 0.1111 - val_acc: 0.9758\n",
      "Epoch 18/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1119 - acc: 0.9755 - val_loss: 0.1100 - val_acc: 0.9758\n",
      "Epoch 19/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1125 - acc: 0.9753 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 20/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1118 - acc: 0.9755 - val_loss: 0.1113 - val_acc: 0.9758\n",
      "Epoch 21/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1112 - acc: 0.9756 - val_loss: 0.1103 - val_acc: 0.9758\n",
      "Epoch 22/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1114 - acc: 0.9755 - val_loss: 0.1101 - val_acc: 0.9758\n",
      "Epoch 23/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1121 - acc: 0.9753 - val_loss: 0.1098 - val_acc: 0.9758\n",
      "Epoch 24/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1108 - acc: 0.9756 - val_loss: 0.1105 - val_acc: 0.9758\n",
      "Epoch 25/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1118 - acc: 0.9753 - val_loss: 0.1097 - val_acc: 0.9758\n",
      "Epoch 26/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1104 - acc: 0.9756 - val_loss: 0.1096 - val_acc: 0.9758\n",
      "Epoch 27/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1100 - acc: 0.9758 - val_loss: 0.1099 - val_acc: 0.9758\n",
      "Epoch 28/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1097 - acc: 0.9759 - val_loss: 0.1094 - val_acc: 0.9758\n",
      "Epoch 29/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1102 - acc: 0.9756 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 30/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1114 - acc: 0.9752 - val_loss: 0.1090 - val_acc: 0.9758\n",
      "Epoch 31/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1096 - acc: 0.9757 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 32/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1093 - acc: 0.9758 - val_loss: 0.1092 - val_acc: 0.9758\n",
      "Epoch 33/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1095 - acc: 0.9757 - val_loss: 0.1095 - val_acc: 0.9759\n",
      "Epoch 34/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1104 - acc: 0.9755 - val_loss: 0.1085 - val_acc: 0.9758\n",
      "Epoch 35/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1088 - acc: 0.9758 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 36/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1094 - acc: 0.9757 - val_loss: 0.1088 - val_acc: 0.9758\n",
      "Epoch 37/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1099 - acc: 0.9755 - val_loss: 0.1084 - val_acc: 0.9759\n",
      "Epoch 38/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1094 - acc: 0.9756 - val_loss: 0.1087 - val_acc: 0.9758\n",
      "Epoch 39/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1091 - acc: 0.9756 - val_loss: 0.1089 - val_acc: 0.9758\n",
      "Epoch 40/40\n",
      "701/701 [==============================] - 15s 22ms/step - loss: 0.1087 - acc: 0.9758 - val_loss: 0.1088 - val_acc: 0.9759\n",
      "\n",
      "PFN AUC: 0.6545994540481388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# configs\n",
    "Phi_sizes, F_sizes = (256, 256, 512), (256, 256, 512)\n",
    "num_epoch = 40\n",
    "batch_size = 2048\n",
    "\n",
    "print('Model summary:')\n",
    "\n",
    "# build architecture\n",
    "pfn = PFN(input_dim=X.shape[-1], Phi_sizes=Phi_sizes, F_sizes=F_sizes)\n",
    "\n",
    "# now train the model\n",
    "pfn.fit(X_train, Y_train,\n",
    "        epochs=num_epoch,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        verbose=1)\n",
    "\n",
    "# get predictions on test data\n",
    "preds = pfn.predict(X_test, batch_size=1000)\n",
    "\n",
    "# get ROC curve\n",
    "pfn_fp, pfn_tp, threshs = roc_curve(Y_test[:,1], preds[:,1])\n",
    "\n",
    "# get area under the ROC curve\n",
    "auc = roc_auc_score(Y_test[:,1], preds[:,1])\n",
    "print()\n",
    "print('PFN AUC:', auc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200bf30c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
