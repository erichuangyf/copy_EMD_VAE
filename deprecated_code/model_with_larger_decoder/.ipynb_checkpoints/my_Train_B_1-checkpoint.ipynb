{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on B-jets [bug fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "#from scipy import linalg as LA\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.tf_sinkhorn import ground_distance_tf_nograd, sinkhorn_knopp_tf_scaling_stabilized_class\n",
    "import utils.VAE_model_tools\n",
    "from utils.VAE_model_tools import build_and_compile_annealing_vae, betaVAEModel, reset_metrics\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(dir_path):\n",
    "    ''' Creates a directory (or nested directories) if they don't exist.\n",
    "    '''\n",
    "    if not osp.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    return dir_path\n",
    "\n",
    "def ptetaphiE_to_Epxpypz(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    px = pt * np.cos(phi)\n",
    "    py = pt * np.sin(phi)\n",
    "    pz = pt * np.sinh(eta)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = E\n",
    "    newjets[:,:,1] = px\n",
    "    newjets[:,:,2] = py\n",
    "    newjets[:,:,3] = pz\n",
    "    \n",
    "    return newjets\n",
    "\n",
    "def ptetaphiE_to_ptyphim(jets):\n",
    "    pt = jets[:,:,0]\n",
    "    eta = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    E = jets[:,:,3]\n",
    "    \n",
    "    pz = pt * np.sinh(eta)\n",
    "    y = 0.5*np.nan_to_num(np.log((E+pz)/(E-pz)))\n",
    "    \n",
    "    msqr = np.square(E)-np.square(pt)-np.square(pz)\n",
    "    msqr[np.abs(msqr) < 1e-6] = 0\n",
    "    m = np.sqrt(msqr)\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = y\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = m\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def ptyphim_to_ptetaphiE(jets):\n",
    "    \n",
    "    pt = jets[:,:,0]\n",
    "    y = jets[:,:,1]\n",
    "    phi = jets[:,:,2]\n",
    "    m = jets[:,:,3]\n",
    "    \n",
    "    eta = np.nan_to_num(np.arcsinh(np.sinh(y)*np.sqrt(1+np.square(m/pt))))\n",
    "    pz = pt * np.sinh(eta)\n",
    "    E = np.sqrt(np.square(pz)+np.square(pt)+np.square(m))\n",
    "    \n",
    "    newjets = np.zeros(jets.shape)\n",
    "    newjets[:,:,0] = pt\n",
    "    newjets[:,:,1] = eta\n",
    "    newjets[:,:,2] = phi\n",
    "    newjets[:,:,3] = E\n",
    "    \n",
    "    return newjets\n",
    "    \n",
    "def center_jets_ptetaphiE(jets):\n",
    "    cartesian_jets = ptetaphiE_to_Epxpypz(jets)\n",
    "    sumjet_cartesian = np.sum(cartesian_jets,axis=1)\n",
    "    \n",
    "    sumjet_phi = np.arctan2(sumjet_cartesian[:,2],sumjet_cartesian[:,1])\n",
    "    sumjet_y = 0.5*np.log((sumjet_cartesian[:,0] + sumjet_cartesian[:,-1])/(sumjet_cartesian[:,0] - sumjet_cartesian[:,-1]))\n",
    "    \n",
    "    ptyphim_jets = ptetaphiE_to_ptyphim(jets)\n",
    "    #print(ptyphim_jets[:3,:,:])\n",
    "    \n",
    "    transformed_jets = np.copy(ptyphim_jets)\n",
    "    transformed_jets[:,:,1] = ptyphim_jets[:,:,1] - sumjet_y[:,None]\n",
    "    transformed_jets[:,:,2] = ptyphim_jets[:,:,2] - sumjet_phi[:,None]\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] + np.pi\n",
    "    transformed_jets[:,:,2] = np.mod(transformed_jets[:,:,2],2*np.pi)\n",
    "    transformed_jets[:,:,2] = transformed_jets[:,:,2] - np.pi\n",
    "\n",
    "    transformed_jets[transformed_jets[:,:,0] == 0] = 0\n",
    "    \n",
    "    newjets = ptyphim_to_ptetaphiE(transformed_jets)\n",
    "    return newjets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess train/val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 150)\n",
      "Memory in GB: 2.250075340270996\n"
     ]
    }
   ],
   "source": [
    "# path to file\n",
    "fn =  '/global/home/users/yifengh3/data/B_background.h5'\n",
    "\n",
    "# Option 1: Load everything into memory\n",
    "df = pandas.read_hdf(fn,stop=1000000)\n",
    "print(df.shape)\n",
    "print(\"Memory in GB:\",sum(df.memory_usage(deep=True)) / (1024**3)+sum(df.memory_usage(deep=True)) / (1024**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file contains, for each event, 50 particles (with zero padding), each particle with pT, eta, phi\n",
    "data = df.values.reshape((-1,50,3))\n",
    "\n",
    "# Normalize pTs so that HT = 1\n",
    "HT = np.sum(data[:,:,0],axis=-1)\n",
    "data[:,:,0] = data[:,:,0]/HT[:,None]\n",
    "# Energy column DNE here, so dont need to normalize the data\n",
    "# data[:,:,-1] = data[:,:,-1]/HT[:,None]\n",
    "\n",
    "# Center jet (optional)\n",
    "# cant center the jets since E missing here\n",
    "# data = center_jets_ptetaphiE(data)\n",
    "\n",
    "# Inputs x to NN will be: pT, eta, cos(phi), sin(phi), log E\n",
    "# Separated phi into cos and sin for continuity around full detector, so make things easier for NN.\n",
    "# Also adding the log E is mainly because it seems like it should make things easier for NN, since there is an exponential spread in particle energies.\n",
    "# Feel free to change these choices as desired. E.g. px, py might be equally as good as pt, sin, cos.\n",
    "sig_input = np.zeros((len(data),50,4))\n",
    "sig_input[:,:,:2] = data[:,:,:2]\n",
    "sig_input[:,:,2] = np.cos(data[:,:,2])\n",
    "sig_input[:,:,3] = np.sin(data[:,:,2])\n",
    "# no input from energy for B jets\n",
    "# sig_input[:,:,4] = np.log(data[:,:,3]+1e-8)\n",
    "\n",
    "\n",
    "data_x = sig_input\n",
    "# Event 'labels' y are [pT, eta, phi], which is used to calculate EMD to output which is also pT, eta, phi.\n",
    "data_y = data\n",
    "\n",
    "\n",
    "train_x = data_x[:800000]\n",
    "train_y = data_y[:800000]\n",
    "valid_x = data_x[800000:]\n",
    "valid_y = data_y[800000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /global/home/users/yifengh3/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:167: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, 50, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 50, 2048)     10240       inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 50, 2048)     0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 50, 2048)     4196352     re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 50, 2048)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 50, 1028)     2106372     re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 50, 1028)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 50, 1024)     1053696     re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 50, 1024)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 1024)         0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1028)         1053700     tf.math.reduce_sum[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 1028)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1028)         1057812     re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 1028)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1028)         1057812     re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 1028)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          526848      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 128)          65664       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 128)          65664       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            multiple             11194160    inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.stack (TFOpLambda)           (2, None, 128)       0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 50, 3)        11917516    encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder_gauss_distribution (Dis multiple             0           tf.stack[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 23,111,677\n",
      "Trainable params: 23,111,676\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "output_dir = '/global/home/users/yifengh3/B_result/'\n",
    "\n",
    "experiment_name = 'B_train_decoder_fixed'\n",
    "train_output_dir = create_dir(osp.join(output_dir, experiment_name))\n",
    "vae, encoder, decoder = build_and_compile_annealing_vae(optimizer=keras.optimizers.Adam(lr=0.001,clipnorm=0.1),\n",
    "                                    encoder_conv_layers = [2048,2048,1028,1024],\n",
    "                                    dense_size = [1028,1028,1028,512],\n",
    "                                    decoder_sizes = [4096,2048,1028,512,512],\n",
    "                                    numItermaxinner = 40,   # EMD approximation params\n",
    "                                    numIter=10,\n",
    "                                    reg_init = 1.,\n",
    "                                    reg_final = 0.01,\n",
    "                                    stopThr=1e-3,\n",
    "                                    num_inputs=4,           # Size of x (e.g. pT, eta, sin, cos, log E)\n",
    "                                    num_particles_in=50)    # Num particles per event.\n",
    "\n",
    "batch_size=150\n",
    "save_period=2\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=0)\n",
    "modelcheckpoint = keras.callbacks.ModelCheckpoint(train_output_dir + '/model_weights_{epoch:02d}.hdf5', save_freq = save_period*5000, save_weights_only=True)\n",
    "reset_metrics_inst = reset_metrics()\n",
    "\n",
    "callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "\n",
    "\n",
    "# Need to train on at least one example before model params can be loaded for annoying reasons.\n",
    "\n",
    "# history = vae.fit(x=train_x[:10], y=train_y[:10], batch_size=batch_size,\n",
    "#                 epochs=1,verbose=1,#initial_epoch=int(vae.optimizer.iterations/numbatches),\n",
    "#                 validation_data = (valid_x[:10],valid_y[:10]),\n",
    "#                 callbacks = callbacks\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "z_sampling (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4096)         528384      z_sampling[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 4096)         0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2048)         8390656     re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 2048)         0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1028)         2106372     re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 1028)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 512)          526848      re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 512)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 512)          262656      re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 512)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 200)          102600      re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 4)        0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 50)           0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 50)           0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 50, 1)        0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.atan2 (TFOpLambda)      (None, 50)           0           tf.__operators__.getitem_2[0][0] \n",
      "                                                                 tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Softmax)               (None, 50, 1)        0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 50, 1)        0           reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.expand_dims (TFOpLambda)     (None, 50, 1)        0           tf.math.atan2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 3)        0           softmax[0][0]                    \n",
      "                                                                 tf.__operators__.getitem_1[0][0] \n",
      "                                                                 tf.expand_dims[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 11,917,516\n",
      "Trainable params: 11,917,516\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import keras\n",
    "# generate the model arg file\n",
    "vae_args_file = os.path.join(train_output_dir,\"vae_args.dat\")\n",
    "vae_arg_dict = {\"encoder_conv_layers\" : [2048,2048,1028,1024],\n",
    "                \"dense_size\" :[1028,1028,1028,512],\n",
    "                \"decoder_sizes\" : [4096,2048,1028,512,512],\n",
    "                \"numItermaxinner\" : 40,   # EMD approximation params\n",
    "                \"numIter\":10,\n",
    "                \"reg_init\" : 1.,\n",
    "                \"reg_final\" : 0.01,\n",
    "                \"stopThr\":1e-3,\n",
    "                \"num_inputs\":4,           # Size of x (e.g. pT, eta, sin, cos, log E)\n",
    "                \"num_particles_in\":50}\n",
    "\n",
    "with open(vae_args_file,'w') as file:\n",
    "  file.write(json.dumps(vae_arg_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:AutoGraph could not transform <function build_and_compile_annealing_vae.<locals>.recon_loss at 0x7f13dc076f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function build_and_compile_annealing_vae.<locals>.recon_loss at 0x7f13dc076f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method sinkhorn_knopp_tf_scaling_stabilized_class.do_dense of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f13843159d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method sinkhorn_knopp_tf_scaling_stabilized_class.do_dense of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f13843159d0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method sinkhorn_knopp_tf_stabilized_alt_class.do_dense of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f138427c970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method sinkhorn_knopp_tf_stabilized_alt_class.do_dense of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f138427c970>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  35/1000 [>.............................] - ETA: 4:14 - loss: 195519062.4000 - recon_loss: 3.9104 - KL loss: 631.6257 - beta: 1.0000e-04"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-383e0a8d334c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_epoch = 0\n",
    "steps_per_epoch = 1000\n",
    "save_period = 40\n",
    "\n",
    "reduceLR = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1), patience=5, verbose=1, mode='auto', min_delta=1e-4, cooldown=0, min_lr=1e-8)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0., patience=5, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")\n",
    "\n",
    "for beta in np.concatenate((np.logspace(-4,np.log10(7),20),\n",
    "               np.logspace(np.log10(7),-5,20)[1:],\n",
    "                np.logspace(-5,np.log10(7),20)[1:])):\n",
    "    modelcheckpoint = keras.callbacks.ModelCheckpoint(train_output_dir + '/model_weights_{epoch:02d}.hdf5', save_freq = save_period*steps_per_epoch, save_weights_only=True)\n",
    "    callbacks=[tf.keras.callbacks.CSVLogger(train_output_dir + '/log.csv', separator=\",\", append=True),\n",
    "            reduceLR,earlystop,\n",
    "            modelcheckpoint,\n",
    "            reset_metrics_inst]\n",
    "    vae.beta.assign(beta)\n",
    "    K.set_value(vae.optimizer.lr,3e-5)\n",
    "    \n",
    "    my_history = vae.fit(x=train_x, y=train_y, batch_size=batch_size,\n",
    "                epochs=10000,verbose=1,\n",
    "                validation_data = (valid_x[:200*batch_size],valid_y[:200*batch_size]),\n",
    "                callbacks = callbacks,\n",
    "                initial_epoch=init_epoch,\n",
    "                steps_per_epoch = steps_per_epoch\n",
    "              )\n",
    "    init_epoch = my_history.epoch[-1]\n",
    "    vae.save_weights(train_output_dir + '/model_weights_end_' + str(init_epoch) + '_' + \"{:.1e}\".format(beta) + '.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
